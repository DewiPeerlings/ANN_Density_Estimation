{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.constraints import max_norm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import expon\n",
    "\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "import random\n",
    "from scipy.misc import comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TUNING PARAMETERS ###\n",
    "\n",
    "observations = 5999                    # Sample construction\n",
    "X_val_size = 999\n",
    "n_split = 5\n",
    "                      \n",
    "N_nodes = [1, 2, 3]                    # Design MLP                       \n",
    "t=0\n",
    "H_layers = [1, 2, 3, 4, 5, 10, 25, 50, 100]\n",
    "\n",
    "m = 0                                  # Distribution parameters\n",
    "sd = 1               \n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "lambd = 0.5\n",
    "a = 0.25\n",
    "b = 0.75\n",
    "\n",
    "                                       # Grid search hyperparameters\n",
    "batch_size = [50, 100, 500, 1000]\n",
    "epochs = [50, 100, 500]\n",
    "\n",
    "dropout_rate = [0.1, 0.3, 0.5]\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3, 0.5]\n",
    "weight_constraint = [0, 3, 5]\n",
    "\n",
    "neurons = [1, 2, 3, 4, 5, 10, 25, 50, 100]\n",
    "                                       #grid_search or random_search?\n",
    "search = \"random_search\"\n",
    "n_iter_search = 10\n",
    "\n",
    "t_size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FUNCTIONS ###\n",
    "\n",
    "def create_dataset():\n",
    "    x = np.array([[random.expovariate(lambd) for i in range(N_nodes[t])] for i in range(0, observations+1)])\n",
    "    #y = np.array([0.95*i/observations+0.05 for i in range(0,observations+1)])\n",
    "    \n",
    "    #check dimensionality\n",
    "    print('dimensionality of x :', np.shape(x))\n",
    "    #print('dimensionality of y: ', np.shape(y))\n",
    "    \n",
    "    #sort\n",
    "    x_sorted = np.sort(x,0)\n",
    "\n",
    "    #correlation\n",
    "    #for i in range(N_nodes[t]):\n",
    "    #    print(\"correlation for \" +str(N_nodes[t])+ \": \",pearsonr(x_sorted[:,0], y))\n",
    "    \n",
    "    print('\\n')\n",
    "    #return (x_sorted, y)\n",
    "    return x_sorted\n",
    "\n",
    "def create_targetset():\n",
    "    #x = np.array([[random.expovariate(lambd) for i in range(N_nodes[t])] for i in range(0, observations+1)])\n",
    "    #y = np.array([0.95*i/observations+0.05 for i in range(0,observations+1)])\n",
    "    y = np.sort(np.array([random.uniform(0,1) for i in range(0,observations+1)]))\n",
    "    \n",
    "    #check dimensionality\n",
    "    #print('dimensionality of x :', np.shape(x))\n",
    "    print('dimensionality of y: ', np.shape(y))\n",
    "    \n",
    "    #sort\n",
    "    #x_sorted = np.sort(x,0)\n",
    "\n",
    "    #correlation\n",
    "    #for i in range(N_nodes[t]):\n",
    "    #    print(\"correlation for \" +str(N_nodes[t])+ \": \",pearsonr(x_sorted[:,0], y))\n",
    "    \n",
    "    print('\\n')\n",
    "    #return (x_sorted, y)\n",
    "    return y\n",
    "\n",
    "def scale(x):\n",
    "    ### scale ###\n",
    "    mean = np.mean(x, axis=0)\n",
    "    var = np.var(x, axis=0)\n",
    "    print(\"mean is: \", mean)\n",
    "    print(\"variance is: \", var)\n",
    "\n",
    "    x_scaled = np.array([(i-mean)/np.sqrt(var) for i in x])\n",
    "    \n",
    "    print('\\n')\n",
    "    return x_scaled\n",
    "\n",
    "\n",
    "def plot_dataset(x, y):\n",
    "    \n",
    "    for i in range(N_nodes[t]):\n",
    "        plt.scatter(x[:,i], y, c=y)\n",
    "        plt.ylabel('Cumulative Probability < RV value')\n",
    "        plt.xlabel('Random Variable (RV) value')\n",
    "        plt.plot(x[:,i], expon.cdf(x[:,i], scale=1/lambd), label=\"actual CDF\")\n",
    "        plt.colorbar(ticks=np.linspace(min(y), max(y), 10, endpoint=True))\n",
    "        plt.savefig('ToymodelNNA EXP(1.5) plot_dataset obs'+str(observations+1)+': N'+str(i)+'.png')\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def plot_cdf(X_train, Y_train, X_test, Y_test, X_train_scaled, X_test_scaled, predictions):\n",
    "        for i in range(N_nodes[t]):\n",
    "            plt.scatter(X_test[:,i], Y_test, label='test set')\n",
    "            plt.scatter(X_test[:,i], predictions, label='fitted set')\n",
    "            plt.scatter(X_test[:,i], expon.cdf(X_test[:,i],scale=1/lambd), label=\"actual CDF\")\n",
    "\n",
    "            plt.ylabel('Cumulative Probability < RV value')\n",
    "            plt.xlabel('Random Variable (RV) value')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "def plot_est_cdf(X_train, Y_train, X_test, Y_test, X_train_scaled, X_test_scaled, predictions):\n",
    "        for i in range(N_nodes[t]):\n",
    "            plt.scatter(X_test[:,i], Y_test, label='test set')\n",
    "            plt.scatter(X_test[:,i], predictions, label='fitted set')\n",
    "            plt.scatter(X_test[:,i], expon.cdf(X_test[:,i],scale=1/lambd), label=\"actual CDF\")\n",
    "\n",
    "            plt.ylabel('Cumulative Probability < RV value')\n",
    "            plt.xlabel('Random Variable (RV) value')\n",
    "            plt.legend()\n",
    "            plt.savefig('ToymodelNNA EXP(1.5) plot_cdf hyperparameters H_layers'+str(dict_H_layers[np.argmin(best_score)])+', neurons'+str(dict_neurons[np.argmin(best_score)])+', epochs'+str(dict_epochs[np.argmin(best_score)])+', batch_size'+str(dict_batch_size[np.argmin(best_score)])+', learn_rate'+str(dict_learn_rate[np.argmin(best_score)])+'weight_constraint'+str(dict_weight_constraint[np.argmin(best_score)])+': N'+str(i)+'.png')\n",
    "            plt.show()\n",
    "        \n",
    "def create_model(H_layers=1, optimizer='Adam', init=initializers.RandomNormal(mean=0, stddev=0.25, seed=None), activation='sigmoid', dropout_rate=0.0, learn_rate=0.01, neurons=1, weight_constraint=0):\n",
    "#def create_model(optimizer, init, dropout_rate, learn_rate, activation, neurons, weight_constraint):\n",
    "    ### CREATE MODEL ###\n",
    "    MLP = Sequential()\n",
    "    #MLP.add(Dropout(dropout_rate, input_shape=(N_nodes[t],)))\n",
    "    MLP.add(Dense(neurons, input_dim=N_nodes[t], kernel_initializer=init, activation=activation, kernel_constraint=max_norm(weight_constraint)))    #hidden layer\n",
    "    #MLP.add(Dropout(dropout_rate))\n",
    "    for h in range(1,H_layers):                                                                     #multiple hidden layers\n",
    "        MLP.add(Dense(neurons, kernel_initializer=init, activation=activation, kernel_constraint=max_norm(weight_constraint)))\n",
    "        #MLP.add(Dropout(dropout_rate))\n",
    "    #MLP.add(Dense(1, kernel_initializer=init, activation='sigmoid'))                                 #output layer\n",
    "    MLP.add(Dense(1, kernel_initializer=init))\n",
    "    MLP.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return MLP\n",
    "\n",
    "def train_ANN(search, X_train, Y_train, X_test):\n",
    "    \n",
    "    model = keras.wrappers.scikit_learn.KerasRegressor(build_fn=create_model, verbose=0)\n",
    "    print('Keras wrapper done')\n",
    "    param = dict(epochs=epochs, batch_size=batch_size, neurons=neurons, H_layers=H_layers, learn_rate=learn_rate, weight_constraint=weight_constraint)\n",
    "    #param = dict(neurons=neurons, H_layers=H_layers, learn_rate=learn_rate, weight_constraint=weight_constraint)\n",
    "    \n",
    "    if (search == 'random_search'):\n",
    "        print('RANDOM SEARCH')\n",
    "        grid = RandomizedSearchCV(estimator=model, param_distributions=param, n_iter=n_iter_search, n_jobs=1)\n",
    "        print('Grid is prepared')\n",
    "        start = time()\n",
    "        grid.fit(X_train, Y_train)\n",
    "        #grid.fit(X_train, Y_train, batch_size=500, epochs=1000)\n",
    "        print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "              \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    else:\n",
    "        print('GRIDSEARCH')\n",
    "        grid = GridSearchCV(estimator=model, param_grid=param, n_jobs=1)\n",
    "        print('Grid is prepared')\n",
    "        start = time()\n",
    "        grid.fit(X_train, Y_train)\n",
    "        #grid.fit(X_train, Y_train, batch_size=500, epochs=1000)\n",
    "        print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "              % (time() - start, len(grid.cv_results_['params'])))\n",
    "\n",
    "    # summarize results (smallest loss?)\n",
    "    print(\"Best: %f using %s\" % (-grid.best_score_, grid.best_params_))\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    params = grid.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (-mean, stdev, param))\n",
    "    \n",
    "    predictions = grid.best_estimator_.predict(X_test)\n",
    "    \n",
    "    print('\\n')\n",
    "    return (grid, predictions)\n",
    "\n",
    "def run_ANN(X_train, Y_train, X_test):\n",
    "    \n",
    "    model = create_model(H_layers=H_layers, learn_rate=learn_rate, neurons=neurons, weight_constraint=weight_constraint)\n",
    "    print('Keras wrapper done')\n",
    "    model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['mae'])\n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print('\\n')\n",
    "    return (model, predictions)\n",
    "\n",
    "def activation_function(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "### CHECK PROCEDURE ON TEST SET ###\n",
    "\n",
    "def run_ANN_manually(X_val, X_val_scaled):\n",
    "    #assuming biases are included\n",
    "    b = 0\n",
    "    k = 0\n",
    "    #print('k', k)\n",
    "    temp_saved = np.zeros([len(X_val_scaled), H_layers+1, neurons])\n",
    "    predictions = np.zeros([len(X_val_scaled)])\n",
    "    #print('temp_saved', temp_saved)\n",
    "    while (H_layers-k)>=0:\n",
    "        #print('while (H_layers-k)>=0:' ,H_layers-k)\n",
    "        if (k==0):\n",
    "            #print('k==0')\n",
    "            for i in range(len(X_val_scaled)):\n",
    "                #print('i', i)\n",
    "                for j in range(neurons):\n",
    "                    #print('j', j)\n",
    "                    for l in range(N_nodes[t]):\n",
    "                        #print('l', l)\n",
    "                        temp_saved[i][k][j] += X_val_scaled[i][l]*weights[b][l][j]\n",
    "                        #print('temp_saved', temp_saved)\n",
    "                    temp_saved[i][k][j] += 1*weights[b+1][j]\n",
    "                    #print('temp_saved', temp_saved)\n",
    "                    temp_saved[i][k][j] = activation_function(temp_saved[i][k][j])\n",
    "            #print('temp_saved', temp_saved)\n",
    "            b += 2\n",
    "            k += 1\n",
    "        elif((H_layers-k)>0 and k!=0):\n",
    "            #print('(H_layers-k)>0 and k!=0')\n",
    "            #print('k', k)\n",
    "            for i in range(len(X_val_scaled)):\n",
    "                #print('i', i)\n",
    "                for j in range(neurons):\n",
    "                    #print('j', j)\n",
    "                    for l in range(neurons):\n",
    "                        #print('l', l)\n",
    "                        temp_saved[i][k][j] += temp_saved[i][k-1][l]*weights[b][l][j]\n",
    "                        #print('temp_saved', temp_saved)\n",
    "                    temp_saved[i][k][j] += 1*weights[b+1][j]\n",
    "                    #print('1*weights[k+2][j]', 1*weights[k+2][j])\n",
    "                    #print('temp_saved', temp_saved)\n",
    "                    temp_saved[i][k][j] = activation_function(temp_saved[i][k][j])\n",
    "            #print('temp_saved', temp_saved)\n",
    "            b += 2\n",
    "            k += 1\n",
    "        elif(H_layers-k)==0:\n",
    "            #print('(H_layers-k)==0')\n",
    "            #print('k', k)\n",
    "            for i in range(len(X_val_scaled)):\n",
    "                #print('i', i)\n",
    "                for l in range(neurons):\n",
    "                    #print('l', l)\n",
    "                    temp_saved[i][k][0] += temp_saved[i][k-1][l]*weights[b][l][0]\n",
    "                    predictions[i] += temp_saved[i][k-1][l]*weights[b][l][0]\n",
    "                    #print('temp_saved', temp_saved)\n",
    "                temp_saved[i][k][0] += 1*weights[b+1][0]\n",
    "                predictions[i] += 1*weights[b+1][0]\n",
    "                #print('temp_saved', temp_saved)\n",
    "                #temp_saved[i][k][0] = activation_function(temp_saved[i][k][0])\n",
    "                #predictions[i] = activation_function(predictions[i])\n",
    "            #print('temp_saved', temp_saved)\n",
    "            k += 1                                                     #stop while-loop\n",
    "\n",
    "    plot_cdf(X_test, Y_test, X_val, Y_val, X_test_scaled, X_val_scaled, predictions)\n",
    "\n",
    "    return (temp_saved, predictions)\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))*(1-1/(1+math.exp(-x)))\n",
    "\n",
    "def derivative_revised(): \n",
    "    #i = len(temp_saved[0])-1\n",
    "    triangle = H_layers -2\n",
    "    heart = len(weights)-2\n",
    "    print('iterator temp_saved triangle: ', triangle, 'iterator weights heart: ', heart)\n",
    "\n",
    "    #temp_layers (neurons middle layers)\n",
    "    if H_layers > 1:\n",
    "        print('STEP LAYERS')\n",
    "        saved_layers = dict()\n",
    "        for q in range(0, (H_layers-1)):\n",
    "            print('NEW LAYER')\n",
    "            print('q', q)\n",
    "            saved_layers[q] = np.zeros([len(predictions), neurons])\n",
    "            if(q==0):\n",
    "                #print('IF')\n",
    "                for obs in range(len(predictions)):\n",
    "                    #print('NEW OBS')\n",
    "                    #print('obs', obs)\n",
    "                    for j in range(neurons):\n",
    "                        #print('j', j)\n",
    "                        temp_layers = 0\n",
    "                        for k in range(neurons):\n",
    "                            #print('k', k)\n",
    "                            temp_sum = 0\n",
    "                            for p in range(neurons):\n",
    "                                #print('p', p)\n",
    "                                #print('+temp_saved[obs][triangle][p]', 'temp_saved[obs][',triangle,'][',p,']')\n",
    "                                #print('*weights[heart-2][p][k]', 'weights[',heart-2,'][',p,'][',k,']')\n",
    "                                temp_sum += temp_saved[obs][triangle][p]*weights[heart-2][p][k]\n",
    "                            #print('+weights[heart-1][k]', 'weights[',heart-1,'][',k,']')\n",
    "                            temp_sum += weights[heart-1][k]\n",
    "                            #print('----')\n",
    "                            #print('weights[heart][k][0]', 'weights[',heart,'][',k,'][0]')\n",
    "                            #print('weights[heart-2][j][k]', 'weights[',heart-2,'][',j,'][',k,']')\n",
    "                            temp_layers += weights[heart][k][0]*derivative_sigmoid(temp_sum)*weights[heart-2][j][k]\n",
    "                        saved_layers[q][obs][j] = temp_layers\n",
    "            else: \n",
    "                #print('ELSE')\n",
    "                for obs in range(len(predictions)):\n",
    "                    #print('NEW OBS')\n",
    "                    #print('obs', obs)\n",
    "                    for j in range(neurons):\n",
    "                        #print('j', j)\n",
    "                        temp_layers = 0\n",
    "                        for k in range(neurons):\n",
    "                            #print('k', k)\n",
    "                            temp_sum = 0\n",
    "                            for p in range(neurons):\n",
    "                                #print('p', p)\n",
    "                                #print('+temp_saved[obs][triangle][p]', 'temp_saved[obs][',triangle,'][',p,']')\n",
    "                                #print('*weights[heart-2][p][k]', 'weights[',heart-2,'][',p,'][',k,']')\n",
    "                                temp_sum += temp_saved[obs][triangle][p]*weights[heart-2][p][k]\n",
    "                            #print('+weights[heart-1][k]', 'weights[',heart-1,'][',k,']')\n",
    "                            temp_sum += weights[heart-1][k]\n",
    "                            #print('----')\n",
    "                            #print('weights[heart][k][0]', 'weights[',heart,'][',k,'][0]')\n",
    "                            #print('weights[heart-2][j][k]', 'weights[',heart-2,'][',j,'][',k,']')\n",
    "                            temp_layers += saved_layers[q-1][obs][k]*derivative_sigmoid(temp_sum)*weights[heart-2][j][k]\n",
    "                        saved_layers[q][obs][j] = temp_layers\n",
    "            heart -= 2\n",
    "            triangle -= 1\n",
    "\n",
    "    print('iterator temp_saved triangle: ', triangle, 'iterator weights heart: ', heart)\n",
    "\n",
    "    #derivative input layer\n",
    "    print('LAST STEP')\n",
    "    saved_last = np.zeros([len(predictions), N_nodes[t]])\n",
    "    for obs in range(len(predictions)):\n",
    "        #print('NEW OBS')\n",
    "        #print('obs', obs)\n",
    "        for i in range(N_nodes[t]):\n",
    "            #print('i', i)\n",
    "            temp_last = 0\n",
    "            if (H_layers == 1):\n",
    "                #print('IF')\n",
    "                for k in range(neurons):\n",
    "                    #print('k', k)\n",
    "                    temp_sum = 0\n",
    "                    for p in range(N_nodes[t]):\n",
    "                        #print('p', p)\n",
    "                        #print('weights[0][p][k]', 'weights[0][',p,'][',k,']')\n",
    "                        #print('X_val[obs][p]', 'X_val[obs][',p,']')\n",
    "                        temp_sum += weights[0][p][k]*X_val_scaled[obs][p]\n",
    "                    #print('BIAS weights[1][k]', 'weights[1][',k,']')\n",
    "                    temp_sum += weights[1][k]\n",
    "                    #print('derivative_sigmoid')\n",
    "                    #print('weights[2][k][0]', 'weights[2][',k,'][0]')\n",
    "                    #print('weights[0][i][k]', 'weights[0][',i,'][',k,']')\n",
    "                    temp_last += weights[2][k][0]*derivative_sigmoid(temp_sum)*weights[0][i][k]\n",
    "                    #print('temp_last', temp_last)\n",
    "                #print('saved_last[obs][i]', 'saved_last[obs][',i,']')\n",
    "                saved_last[obs][i] = temp_last       \n",
    "            else:\n",
    "                #print('ELSE')\n",
    "                for k in range(neurons):\n",
    "                    #print('k', k)\n",
    "                    temp_sum = 0\n",
    "                    for p in range(N_nodes[t]):\n",
    "                        #print('p', p)\n",
    "                        #print('weights[0][p][k]', 'weights[0][',p,'][',k,']')\n",
    "                        #print('X_val_scaled[obs][p]', 'X_val_scaled[obs][',p,']')\n",
    "                        temp_sum += weights[0][p][k]*X_val_scaled[obs][p]\n",
    "                    #print('BIAS weights[1][k]', 'weights[1][',k,']') \n",
    "                    temp_sum += weights[1][k]\n",
    "                    #print('derivative_sigmoid')\n",
    "                    #print('saved_layers[H_layers-2][obs][k]', 'saved_layers[',H_layers-2,'][obs][',k,']')\n",
    "                    #print('weights[0][i][k]', 'weights[0][',i,'][',k,']')\n",
    "                    temp_last += saved_layers[H_layers-2][obs][k]*derivative_sigmoid(temp_sum)*weights[0][i][k]\n",
    "                saved_last[obs][i] = temp_last \n",
    "\n",
    "    return saved_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality of x : (6000, 1)\n",
      "\n",
      "\n",
      "Simulations\n",
      "dimensionality of y:  (6000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFaCAYAAAApR+W4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd8FNX6+PHPzG52UzaFkNBDr1LECCgqUjRKlV4V9FoA\nv5b7E64XUIgoRRQUC1wsV0W8KggKAoqFroBIC0gXpCWUhPSeLfP7Y8mQCMmGkM0m7PN+vfLKzJnd\nybOb2X3mnDlzjqJpmoYQQgghyp3q6QCEEEIIbyVJWAghhPAQScJCCCGEh0gSFkIIITxEkrAQQgjh\nIZKEhRBCCA+RJCyEEMIrOBwOoqOjGTp0KCNHjuTUqVOFtq9YsYI+ffowYsQIli5dCkBeXh7jx49n\nyJAhPProo5w8eRKAAwcOMGjQIEaMGMG0adNwOBwAfPzxxwwYMICBAwfy888/uw5KE0IIIbzAjz/+\nqE2YMEHTNE3bs2ePNnbsWH1bYmKi1rVrVy05OVmz2+3ayJEjtTNnzmifffaZNnnyZE3TNO348ePa\no48+qmmapvXv31/btWuXpmma9uabb2orVqzQUlNTtc6dO2u5ublaSkqK1qVLF5cxSU1YCCGEV9i1\naxedOnUCoG3btuzfv1/fFhsbS7NmzQgJCUFVVVq3bs3evXs5duwYd999NwANGzbk+PHjAFy4cIHI\nyEgAIiMj2bVrF35+ftSqVYvs7Gyys7NRFMVlTMayfpHukpCQft37qFLFn+TkrDKIpvxJ7J4hsXtG\nZY4dKnf8JY09PDzQbTGUJHkVRStmEMiMjAwsFou+bjAYsNlsGI1G6tWrx7Fjx7h48SIBAQFs27aN\n+vXr06JFCzZs2MC9997L3r17uXDhAna7nYiICH7//Xc6dOjAhg0byM7OBqBmzZr06tULu93OmDFj\nXMZbaZJwWTAaDZ4OodQkds+Q2D2jMscOlTv+ihD79STh4lgsFjIzM/V1h8OB0ehMg8HBwUyaNIln\nnnmGkJAQWrZsSZUqVejSpQvHjx9nxIgRREZG0rJlSwwGAzNnzmTGjBnMnz+fdu3aYTKZ2Lx5M/Hx\n8axbtw6Axx57jMjISNq0aVNkTNIcLYQQwitERkayefNmAGJiYmjatKm+zWazcfDgQb744gvefvtt\n/vrrLyIjI/njjz/o2LEjX375Jd27dyciIgKATZs2MWfOHD799FNSUlK48847CQ4OxtfXF5PJhNls\nJjAwkLS0tGJj8qqasBBCiIrPXTXhqKgotmzZwrBhw9A0jZkzZ7Jq1SqysrIYOnQoAP3798dsNvOP\nf/yD0NBQAN5++23ee+89AgMDmTFjBgD16tXjkUcewc/Pj9tuu43OnTsDsHXrVoYMGYKqqkRGRnLn\nnXcW/1q14hrQK5CyuCYcHh5YJvvxBIndMyR2z6jMsUPljr+ksbvzmnB+E3Fp2Gy2MozE/aQmLIQQ\nokJRVe+5UipJWAghRIXiruboikiSsBBCiApFkrAQQgjhId6UhL2n4V0IIYSoYKQmLIQQokLxppqw\nJGEhhBAViiRhIYQQJWaz2VBVlbS0VPz8/IFrv4fWOeh/FlWqhLo9CcXHx6MoCuHh4W79O6UltygJ\nIcQlmqbpSaHgss1mQ1EU8vLySEq6yKxZ0zlz5gwjRz7CwIFDrrqv2NgzrFy5nHPnzqIoBn79dSOZ\nmRkEB4cwcuQjNG7clIULP2L37h3Exydgt9vw8THRqFFjxo37Nz179uaHH75n0qR/cf78OTRNIyDA\nwoABg1FVhR07fsfhsNO2bSTjx08gIqJuob+flZXF5MkTWb36W9LTncMJ+viYqFmzJl273kt09Cv4\n+/uX+L359ttvWLjwI/bt24vVmofD4SAsrBpRUfcQHT2DwMAgl/tISUnmxRf/zZYtv5KRkU6TJs14\n9NEnGDx4WInjKKmtW3/lzTdfZ/funSiKQmRke/7970m0b39bmf+t6+FNNWG3jpi1d+9e5syZw2ef\nfVaofP369cyfPx+j0cjAgQMZMuTqH9iCZMQsid0TKlvsf/55hKSkJLKzs9myZQOpqZmcOnWSo0eP\nkJPjnOWlevUa3H77HTRt2oyPPnqf+PgLqKqKv7+F+vXrc+edd5Obm8OXX35GUlISDocDs9lMQIAF\nHx8fzGYTDodGQkICeXm52O32K+IICanCunW/6ElQ0zRefnkKX3yxiJSUlCLjV1VVnxz974xGH/r2\n7c+KFV9f9W/+XcuWrVi+/DtCQqroMQwdOoCNG9cV+Zxu3aL48stlJUoCa9Z8x7PPjiU1NfWq2++9\n9z6++GJZsftwxtSfjRvXFyoPCgpi3rz36d69l8s4Sio29gx9+/bkzJnCE9nXr9+A1at/plq1akDF\nGDErODi41M8t6v9RUbmtJvzhhx+ycuVK/Pz8CpVbrVZeffVVli1bhp+fH8OHD6dbt26EhYW5KxQh\nKoX88+G8vDyys7NwODQOHPiDP/88TGpqKt9+u4JTp05iNBqpUqUKBoOB5ORkUlKSi52+7e+SkhI5\ndOjAFeUpKSmcPRvL1q2/XrEtJyeHnJycImO+cl/J9OvXk127nPO1Ll78OR988B+XQwoWlYABbDYr\n3377zZUJWFFRFBVFvfRbUUBROXr8JPPfe49nnh0PGqzfsJbfdu7B1xIK5D9OuZRwnb937TvCspU/\ncsednUDT0DRwXHqNmgYal8v+9/X3qP41qBJQE0VRnftCAQVA4cCJRJZ+t4mbWra+9GY5n5+/DLB3\n316OxmYQXj/yb4lf4YtvN1Gj0W1XPEe7FEv+2t//Bc7thQs1DZYtW47dvy61mtcDIOXcUbJSz3Py\n5Ak+/HABL774UpHvvXAft9WEf/zxR5o1a8a///1vvvrqK7388OHDzJ49m48++giAmTNncsstt9Cj\nR49i92ez2SvEFFtCuBIXF4fRaGT37t2cOXOGH3/8kbVr12Kz2bBarUUmmtJ+FK/3I6yoBgxGE6rB\n5Pxt9NHXnctmVMOlMqMJVTWgGoygGFANBlTVB8VgQFUNKKoPqsGAohpQDT4MHDgYPz9/Nv+6hfMX\n4i89xohqMBZYNqAoBj2JUiihFly+9JhC2+Q7obQSYw+w7asXARg1ahSffvqphyO6LCQkpNTPLa6l\npSJyW034/vvvJzY29oryjIwMAgMvN2MEBASQkZHhcn9lMUF2ZWtaLEhi94zw8ECOH49j7NjH2Lx5\nA5oGPj5GbDabnvyKq72VVMkTqYLR7IeP2YKPOQAfcwAGHz+MJj8MJl+MPr4YTH7O3z7OdaPJ79Jj\nLpcZfC4nVncmsh1HkoFksNSnhqV+oW0OuxWH3YbmcKBp9ku/L/04HDgctkLlaA7ne32VxxZcdtZg\nHYBGndp1uLntLSiKwl/H/+SPP/Y6t6NdepxWYN2BpkGHDh1o0aIligLqpZqtooCC4ixzrvDN119x\n9mwsWv5+Cu4T5+P6DxhE48ZN0Ou4iqIvKwocPnyIr7/+6lK8FKotN2rUmJEPPaI/FrjqfvTKN4Wv\npf79OatWf8vmTRv07UlnD+nLQUGh+me0IjRHe9M14XLvmPX3SZUzMzMLJWUhPGXLll959tmxXLhw\nHig6MVqtVn35emqhimrA5BeEyS/Y+ds/GLN/CCb/4MtJ1jfAuewbgPFS0lWU0vUctdtyseXlYLfm\nkJuVgsNmxW7Lw2HPc/62WbHbcnHYL5Xb8rDbrc7fl9adidOKw2G/lEDt+rpmt+Fw2HDY7WgOGwoa\nGzdswWIJYMb0aL74/FNnYrXbLiedaxQSElLimo6/fwATPv2Czp2dzcEZGfXp0mUKp0+fLvI5jRs3\nZcp/o0vUOSvxcBAvL/uiyJOw22+/g+dGRRWbUHrcVpcNX8/l9x2/FSo3m838v1Fv0/22ukU889o1\nCO3F+m/mcfZsXKHyiIi6jB79ZJn9nbIgSdiNGjVqxKlTp0hJScHf35+dO3fy2GOPlXcYQhAXd4a7\n7upQKKleq6slYUVRMVtC8bVU1X/8AsMwB4Ri9g/G5B98KfGW7OTTlpeNNTeT3IwkMi6expqbefkn\nJwNbbhY2aw52aza2vBxs1mzs1hzncp5z2W7NKXXiK05xJyH33HMfETWd87E+NXYMW3/5mWPHjhW7\nP5PJRF5e3lW31apVm9dfn8srr0Rz9OjhQtv8/f0JDg7h3LmzANSsWZMnnniSzp276o+xWCy88cY7\njBv3DGfOnLli/23atGXq1Bkl7h09duxTxMfH8803X+l/F8DPz4+uXbvy8suvuUwmqqoyb94HTJr0\nL7Zt20JWViaNGjXmwQdHMWzYiBLFUVL169dn7tx5vPHGa+zZs+vSfLftGD9+IjVq1CzTv3W9vOkW\nJbf2jo6NjWXcuHF89dVXhSZOzu8drWkaAwcO5MEHH3S5L+kdLbGXVmpqKt99t5JXX32F1NTUQomj\nqMO/+I+Fgq8lFP/gGvgGVcM/uAb+wTXwCwzD11IVc0BIkU28mubAmp1ObnYaeVkp5GalkpedSm5m\nivP3pXVrdjrW3CysuZlojuI7M5X1R9hs9sVutxXZicrHxwdNc3aUuvpJiML99/fg00+/LJSEjhw5\nzLvvzmXbtl9JTU1D0xyoqoqqqtSsWYtnnhnH7bd35L//fZ99+3Zz/nw8VmsuoaFh9OzZmyeeeBI/\nPz8cDgfLly/j008/ISMjjaFDRzB69P+RlZXFsmVLsFqtDBo0RO8V/Xc2m42VK5ezefNG6tatT2Cg\nhdq1I7j//h4YDNfeNJ+Skswvv2ymevXqgLP3ebt2ra/5mD99+hTx8fG0bt0Gs9l8zXGUlKZpnD59\nClVVr7iFCypGc/T13L+ckJBQhpG4n1uTcFmSJCyxl5SmafTseQ8HDuy/6rarLV/tcQYfXwKq1MYS\nGoEltA4BobWdyTaoGgaj6YrnOOxWcjKSyMlIdP6kJ5KTcZHsdOd6bkYiedlpV62RXu/H8FqebzQa\niYioR40aNTh+/Bjp6en4+vrSpElT7rjjLh5++FGsViuff76I337bio+Pif79B9Khw+388cde2rXr\ngJ+fH7/9thWj0QdnD10Ns9lMhw4dCQpyfW+sK5X5eIfKHX9FSML5t0uVRnx8fBlG4n4yWIeo9FJS\nUnj11eksXnz5fvRrS2oK/iE1CApvSGB4fT3p+gVd+UVgzckgI/E0WakXyEq9QGbKWbJSLpCVep7c\nzGT0+0jKgdlsxsfHhNWah81mw2j0ITIyku7de9OrVx+MRjtBQdWuafCJgl54IfqKsqZNm+nLDzzQ\nv9SxCyGcJAmLSmXHjh0MG9bvintFryXp+gVVJ7hGEwLDGxAU3pCg8PoYTYUTVW5mMoln9pGRFEtG\n4hkykmPJTIrFmnNlT/7S9o4ODQ2jbt26NG7clNOnTxIWVp2bb76Zgwf/ICsrm/btb8NoNNCwYSPu\nuec+jMZr+7hW5tqY8G7SMUuICkLTNB5/fCQbNlweUehakp6iGggMq0dwjWaE1GxOSM1mmP0v34Oo\naQ4yk8+SFr+TtIS/SE84QXriaWy5mSVO7Kqqomkavr6+WCyB1KtXn0ceeZTbbrsDq9VGRESEfu1T\nCOGaJGEhPGzPnt0MGtQHuPbrpQGhEYTWaU1oRGuq1GyOwcdX35abmcT5P7eScv4oafF/kX7xBHZr\n7lX3U3C8ZD8/P/r1G8ScOW+V8hUJIUpKkrAQHnLu3DnuuqvdNT3HaA4gNOJmqka0IbROa8wBl3vF\nZiSdIeXcYVLOHSXl3GGy04rvtFGnTh3mzp3P7bffcWmWGWnSFaK8eVOrkSRhUSHcfHMzsrKySlzr\nNQeEEt6gHWH12xFSqwXqpVuC8rJSOXf0V5LO7CXxzH7yspILPa9g7RagRo0avP7623Tp0tWrzr6F\nqMi86bMoSVh41JYtv/DII85BCVwlYJN/Fao37kh4w9sIqtZIL0+98CcJJ3aReDqGjMTTFNVD+d//\nnsSYMU/j4+NTZvELIcqeJGEh3GzJki+YMmWiy8Rr8PElrH47qje+k5DaN6EoKg67jaQz+0g4uZOE\nk7vIyyxY2728v44dO7Fo0ReYTFfe0yuEEBWBJGFRrhYv/pKXXpro8nFB1RpT86Z7CG/QHoPROXpQ\n6vmjXPjzV+L/+h1rTvoVCXzw4OFMmPACYWGlH21HCOF57qoJOxwOpk6dypEjRzCZTEyfPp169erp\n21euXMknn3yCqqoMHDiQESNGYLVamThxInFxcaiqyrRp02jUqBGHDh3ipZdewmAwUL9+fWbMmIGq\nqnz88cesXr0aRVEYO3YsUVFRxcYkSViUC7vdTqtWjYt9jGo0U73xHdRs0Q1LVecHIyv1vDPxHtta\nqFNVtWrV2b49xq0xCyE8w11JeO3ateTl5bFkyRJiYmKYNWsWCxYs0Le//vrrrF69Gn9/f3r16kWv\nXr3YsWMHNpuNxYsXs2XLFt566y3effdd5s2bx1NPPUXnzp0ZP348GzdupF27dixatIiffvqJ7Oxs\n+vXrJ0lYeN6wYcNYt25dkdtN/lWo3fI+ajTvgtHkj+awk3BiB2cPriPl7EHym5iPHj19zQNWCCEq\nH3cl4V27dtGpUycA2rZty/79hYe2bdasGenp6RiNRjRNQ1EUGjRogN1ux+FwkJGRoX8HtWjRgpSU\nFDRNIzMzE6PRiJ+fH7Vq1SI7O5vs7OwSvQ75RhNus2XLr4we/XCR1339QmpRp1UPwht1RDUYyctK\n4dT+Hzl3eKPeq1lRYOXKn7jpppblGboQwoPcdYtSRkYGFotFXzcYDJeGfHWmwiZNmjBw4ED8/PyI\niooiKCiIzMxM4uLi6NGjB8nJybz33nuAc1aqV155hQULFhAYGMhtt90GOGfw6tWrF3a7nTFjxriM\nSZKwKHO33tqK3NycIrf7hdSi7i39CKvfHoCslHPE/vE98ce26jMGNW3anO+++9mrekkKIZzc9bn/\n+3z2DodDT8CHDx9m48aNrFu3Dn9/f55//nnWrFlDTEwMd911F+PHj+fcuXM8/PDDrFq1ihkzZvD5\n55/TpEkTPv/8c2bNmsVdd91FfHy83vL32GOPERkZSZs2bYqMSZKwKDMXLlzg3nvv0tf/XgP2DaxG\nnZsfIKzhbSiKSnrCcc7sXU3S6Rjym5wVReHQoROlmlJOCHFjcFcSjoyMZMOGDfTs2ZOYmBiaNm2q\nbwsMDMTX1xez2YzBYCA0NJS0tDSCgoL02xqDg4Ox2WzY7XaCg4P1WnW1atXYvXs3wcHB+Pr6YjKZ\nUBSFwMBA0tLSio1JkrAoE23aNNWT7t+Tr9E3kIib+1KtSScU1UBm0mlO7f6G5DN7AWeTMyj89tse\nqlQJLefIhRDeIioqii1btjBs2DA0TWPmzJmF5rofOnQoI0aMwMfHh7p169K/f3+sVisvvPCC3lP6\nueeew9/fn+nTp/Pcc89hNBrx8fFh2rRp1KlTh61btzJkyBBUVSUyMpI777yz2JhkPuFKoqLG/uef\nRxk0qA+apl2ZhBWV6s26UbtNb4wmf7JTz3FmzwoST+2i4P28hw6d8EDkJVNR3/eSkNg9pzLHXxHm\nE27SpEmpn/vnn3+WYSTuJzVhUWq33NKiUPItKLhmS+q2H4pfUA1suZmc2P45F45uAs2h13y//PJr\nbr75lnKPWwhRsXlTXxBJwuKabdq0keee+7+rbjOaLdS9dQhVG9yG5rBz4fB6YveuxJaXiTP3Oj9c\nBw4cL7+AhRCVikzgIEQRbr21ZZG136oNbiMicgg+vhYyLp7gxG+LyE6JAy6f2S5duooWLVqUa8xC\niMpFasJC/M2ZM2fo37/HVZOvyT+Euu0fJKR2a+y2XE7v/IoLR9fDpZvdAfbtO+pVHywhROl503eF\nJGHh0s6dOxg79h9XTcBBtVpRr8NIfHwDSTt3iJO//4+8zES96XnDhm00b16/0nZSEUKUP2mOFuKS\n7OxsnnzyUX1dURQ0TUM1mqjVph/hTTrjsFs5s3spCUc3AhqqqhIQEMCWLbs8FrcQQlQGkoRFkS5c\nOE/v3lcOPm6yhNHgjifwC6lNdupZTm77hJzUs3qv502bthMUFFTu8Qohbgze1BztPXV+cU1Wr15J\n377dC5UpikJgzZY0u/ff+IXU5uKxXzi6dja5aedQFIWHHnqMPXsOSQIWQlwXVVVL/VPZSE1YXOHZ\nZ59kx47f/nYNWKH6Td2pflMPHPY8Tv/+GUknt+tb58//gI4d77pyZ0IIcY28qSYsSVgUcscdkfot\nSIqioKoqGgYi2j9ISJ1byMtM5OS2j8hOPoOiKNSv34ivv17p6bCFEDcQScLCK915561XlBlMAUTc\n/hgBVRuQkXCM0799hC03E0VRmD79Nbp37+WBSIUQN7LK2KxcWpKEBWlpafTqdU+hMkVR8AkIo27H\nJzAFhJFyeiexu75Ac9hRFIWwsHBJwEIIt/CmmrD3nG6IIv09AQP4BtehfqdnMAWEkXD4J+J2fY5y\n6faju+/uypo16z0QqRBC3FikJuzFbDYb3brdcUW5f9UG1LntMVSjmXN7viL51G/6mel77y2kbdu2\n5R2qEMKLSHO08Ar33HPlPJcB4U2p3f4RFNXA2V2fkxYXoyfgNWs2EBISUt5hCiG8jDc1R0sS9lIP\nPHCfvpw/Cpalegtq3joK0IjdsZDMC4f0D8PWrbs9FKkQwttITVjc0KxWK+nphcdy9qvamJq3jgQc\nxP3+CVkXj+kJWIafFEKUJ2+qCXvP6YbQ9ejRVV9WFAXfKvWp1e5hQOHczkXkJP2FqqpUqVJFErAQ\notwpilLqn8pGasJeJiqqk76sqio+gbWodeka8Lnd/yM78Zh+MK9evdaDkQohvJU0R4sbUvfuXfRl\nRVEw+IVSs90jKAYTF2K+JDvhsH4muWnT9iL2IoQQoqxIEvYSPXp0xeFw6OsGk4Uatz6CwRTAxQPL\nyY4/qJ99btiwzVNhCiFEpWxWLi1Jwl6gV697Ck3GoBpMhN/yED7+oaQc30BG3C79oH/ppemeClMI\nIQBpjhY3kN6979WXVVXF4dCo2moQ5uA6ZJzdQ9qJDfoBr6oGOnfu5qlQhRACkJqwuEH07n2vXgPO\nvxc4qGE3/MKbk5N4nOTDqwod7D/9tMlToQohhE6SsKj0Pv304yvKfMNvIqh+J6xZiSQeWIqCAy4d\n7D/9tLm8QxRCiKuS5mhR6X399WLgcg3YGFCNkOYP4LDlkrz/KxRHHsqlA/2HHzZ6MFIhhChMasKi\nUuvXr3uhdcXoR5WWQ1ANJpL2f4U9+2Kh8aCFEMIbOBwOpk6dypEjRzCZTEyfPp169eoBkJCQwLhx\n4/THHjp0iPHjx2M2m1m+fDkAubm5HDp0iC1btvDSSy9x8eJFAOLi4rj55psZPXo0M2fO1PcRExPD\n/Pnzufvuu4uMSZLwDWbAgJ76srMjloPgZn0w+lUh49QvWJP/1Jt6Vq362VNhCiFEkdzVHL127Vry\n8vJYsmQJMTExzJo1iwULFgAQHh7OZ599BsCePXuYO3cuQ4YMwWAwMGDAAABefvllBg4cSFBQEHPn\nzgUgNTWVUaNGMWnSJKpVq6bvY82aNVSrVq3YBAyShG8o586d05fzm6H9arXHHNqEvOS/yDrzi14D\nltGwhBAVlbuao3ft2kWnTs5RA9u2bcv+/fuveIymaUybNo05c+ZgMBj08j/++INjx47x0ksvFXr8\nu+++y0MPPUS1atX0sqysLN59913+97//uYzJbVe/HQ4H0dHRDB06lJEjR3Lq1KlC21euXEn//v0Z\nOHAgX3zxhbvC8BoOh4Onn368UJkxoAaW+t1w5GWQfmw1qqqiqqrUgIUQFZq7xo7OyMjAYrHo6waD\nAZvNVugx69evp0mTJjRs2LBQ+fvvv89TTz1VqCwxMZFt27bpNeV8y5Yto3v37oSGhrp8rS6TcFxc\nHP/4xz+47777iI+PZ9SoUcTGxrrcccFq//jx45k1a1ah7a+//jqffPIJX375JZ988gmpqaku9ymK\nNmxYv0LrqtFMYLO+oKhkHFsNtmwURaFdu9u9qtODEKLyya8wlOanOBaLhczMTH3d4XBgNBZuEF65\nciVDhgwpVJaWlsaJEye4/fbbC5X/8MMP9O7du1CNGWDVqlUMHjy4ZK/V1QOio6N57LHHCAgIIDw8\nnN69ezNhwgSXO3ZV7W/WrBnp6enk5eWhaZokhuswdGjfQuuqquJfPwqDbxVyzv6GLe20fpYYHf2K\nh6IUQoiScVdNODIyks2bnbdjxsTE0LRp0yses3//fiIjIwuV7dixg44dO17x2G3btl1xzTc/r9Ws\nWbNEr9XlNeHk5GTuuusu5syZg6IoDBkyhM8//9zljouq9uefdTRp0oSBAwfi5+dHVFQUQUFBxe6v\nShV/jEZDsY8pifDwwOveh6dcLXa73a4v53fEMoY0xhzeElvGWXLjtupnh7/88ku5xfp3N9r7XllI\n7J5TmeP3dOzu6pgVFRXFli1bGDZsGJqmMXPmTFatWkVWVhZDhw4lKSkJi8VyRTI/ceIEderUuWJ/\nJ06cICIi4oqy2rVrlzgml0nY19eX8+fP60Ht3LkTk8nkcsfFVfsPHz7Mxo0bWbduHf7+/jz//POs\nWbOGHj16FLm/5OQsl3/TlfDwQBIS0l0/sAIqKvbhw/sXWleMfvjVj0JzWMk+8cOlsTgUFiz4xGOv\n/UZ83ysDid1zKnP8JY3d04m6NFRV5ZVXCrcGNmrUSF8ODQ3l22+/veJ5jz/++BVlAN99990VZW3a\ntOE///lPiWNymYQnTpzImDFjOH36NH379iU1NZW33nrL5Y4jIyPZsGEDPXv2vKLaHxgYiK+vL2az\nGYPBQGhoKGlpaSUOWjidPn260LqiKPjWj0L18SfnzEa03BRUVSUsrFqhnntCCFGRedPlSZdJuE2b\nNixbtoyTJ09it9tp2LBhiWrCrqr9Q4cOZcSIEfj4+FC3bl369+/vcp+isBdeuHxjuaIoGEKa4lOl\nCfb0WGwJMXqTzoIFH3kqRCGEuGYybGUBkyZNumr5q6++WuzzXFX7hw8fzvDhw0sSo7iKUaOcvfcU\nRXFeC1Zlp0g5AAAgAElEQVTNmCO6otnzyDn1k75tyZIrm1aEEKIik5pwAR06dNCXbTYb69atu+L+\nKVG+/n5fG4C59t0oRl9yYzeCNR1VVRkz5p/lH5wQQlwnScIF/L2ZeNCgQVKD9bDHH39IX1YUBdVS\nB2NocxxZF3Ak7kdVVRRFoWvXrh6MUgghSkeScDGOHz9OfHy8O2IRJfDnn4f1ZUVRQDHgU7sLmubA\nGrcRRQFVNTBr1lwPRimEEKUnSbiA5s2b6+MQg7MLd8GZJkT5mjnz5ULrhvBIFHMI9ot7UXITUS7V\nguvUiShiD0IIISoKl0n48OHDrh4iyknBZmhVVXEYLKhhkWjWDBwJO/QRYz79dIkHoxRCiOsjNWFg\n3rx5xT7x6aefLvNgRNHy563MHxVL0zQMNTqiqAbsZ7ehaDZQFJ544mmvOoCFEDceb/oOk6kMK4nR\no0cXWlf8a6EENkDLOoeScUJvhu7Uqfi5K4UQoqKTJEzRNV1N00o0i5IoO9HRL+jLiqKgqAao3tF5\nnT7+N70Z+vXX3/FglEIIUTYkCRfwv//9jzfffJPs7Gy9rE6dOvz8s8xJW17i488Cl5uileBmaOaq\nKGlHUaxJoKqYzf6EhYV5OFIhhLh+3jRilstX+vHHH/Ptt9/Ss2dPfv75Z2bMmEGbNm3KIzYBnD17\nttC6YjCjhUaCw4qSuEsfMes///nQQxEKIUTZctdUhhWRyyRctWpVIiIiaNasGUePHmXAgAGcOHGi\nPGITwPTpk4HLB6UjpCUY/VBT/sCg5aKqKv/85789HKUQQojScJmE/fz8+O2332jWrBkbNmwgISFB\nZjwqZ/rZncEPLbgl2LJR0w7piblVq9aeDVAIIcqQ1IQLmDJlCuvXr6dTp06kpKTQo0cPHnroIVdP\nE2Xg6acvz2GpKAr2kFag+mBI3YeKHUVReP/9Tz0YoRBClD1vSsIuO2adOnWK559/HlVVeffdd8sj\nJgEcPXoUuFwLdqj+OAKbgTUdQ8axSnvACSGEK9703eayJrxy5UruueceoqOj2blzZ3nEJIB58+bo\ny85acBvnONGp+1AVDUVR6NbtPg9GKIQQ7uFNNWGXSfidd97h+++/JzIykg8//JDu3bvz1ltvlUds\nXuu5554ECnTGMgZhD2iIYk3BkH1KLx80aJiHIxVCiLLnTUm4RCNmWSwWbr31Vs6fP8+5c+eIiYlx\nd1xey263A5fvCQawBbUCRb1UCwZQCA+v7rkghRDCjSpjMi0tl0n4448/5rvvviMvL48HHniADz74\ngBo1apRHbF7p+eefKbTuMFiw+9dDsaZgzI3TD86XXprhifCEEEKUIZdJOD4+nunTp9OiRYvyiEcU\noKoqOYE3gaJiSj+AeikBT5w4xcORCSGE+0hNuICJEyeWRxwC+Ne/ntbnblYUBbvih82/PqotDVPe\nWZRLQ7nVqiVzBQshblyShIVH5SfiPEtzUAyYMw/r14Lnzl3g6fCEEMKtJAmLcjdz5lR9WVEUHKov\neX4NUO2ZmHLPXDoovefAFEJ4L0nCwIABAxg0aBB9+vQhMDCwPGPySikpSfqBp2kauf5NQDHgm3VE\nrwW/8cZ8j8YohBDlwV1J2OFwMHXqVI4cOYLJZGL69OnUq1dP375v3z5mzZqFpmmEh4cze/ZszGYz\n77//PuvXr8dqtTJ8+HAGDx5MYmIikydPJi0tDbvdzuuvv07dunXZtGkT8+fPR9M0WrZsyUsvvVTs\n6ykyCU+aNIkVK1Ywf/58br/9dgYNGkTHjh3L9h0RACxbtlhfVhQFDQN5vg1QHDmYc0971VmhEEK4\n6ztv7dq15OXlsWTJEmJiYpg1axYLFjgv8WmaxpQpU3jnnXeoV68eS5cuJS4ujoSEBPbs2cOXX35J\ndnY2H3/8MQCzZ8+mT58+9OzZk99++42//vqL0NBQZs+ezaJFiwgNDeXDDz8kOTmZ0NDQImMqcrCO\n9u3bM2PGDDZs2MA999zDwoULuf/++5k/fz7nzp0r47fGu+3atb3Qjea5fvXRVBO+2X/po2N9+qmM\nES2EENdj165ddOrUCYC2bduyf/9+fduJEycICQlh4cKFPPTQQ6SkpNCwYUN+/fVXmjZtylNPPcXY\nsWPp0qULALt37+bChQs88sgjrFq1ig4dOrBnzx6aNm3Ka6+9xogRIwgLCys2AUMJrgmbTCZ69uxJ\nz549SUxM5O233yYqKqpQ8KIMKQo5vo1Bs+Obe0JqwUIIr+Ou772MjAwsFou+bjAYsNlsGI1GkpOT\n2bNnD9HR0dStW5exY8fSqlUrkpOTOXv2LO+99x6xsbE8+eST/PDDD8TFxREUFMTChQuZN28eH374\nIQ0aNGD79u2sWLECf39/HnzwQdq2bUuDBg2KjMnlsJUAJ0+eZN68eYwcOZK4uDhee+216383BABT\npkwALg/TZjXVwmEIwDf3NAasKIrClCnTPBylEEKUH3cNW2mxWMjMzNTXHQ4HRqOzLhoSEkK9evVo\n1KgRPj4+dOrUif379xMSEsJdd92FyWSiYcOGmM1mkpKSCAkJoVu3bgB069ZNf2zr1q0JDw8nICCA\ndu3acejQoWJjKjIJx8fHs3DhQgYMGMDo0aMxGAx89NFHfPTRR/Tq1avEb6YonsNhAy4fdNm+jQHw\ny/1LLwsMDPZkiEIIUa7clYQjIyPZvHkzADExMTRt2lTfFhERQWZmJqdOnQJg586dNGnShFtvvZVf\nfvkFTdO4cOEC2dnZhISEcOutt7Jp0yYAduzYQePGjWnZsiVHjx4lKSkJm83G3r17ady4cbExFdkc\n3b17d+677z4mTpxIhw4dSvbOiVLJvy/YaqyC1RiKyXoeHy0TRVUZNmyUp8MTQohy5a7m6KioKLZs\n2cKwYcPQNI2ZM2eyatUqsrKyGDp0KDNmzGD8+PFomsYtt9yiX//dsWMHgwYNQtM0oqOjMRgMTJgw\ngcmTJ7N48WIsFgtvvPEGwcHBjB8/nscfd84F371790KJ/qqvVdM07Wob/t52XtCqVavo06fPdbwV\n1y4hIf269xEeHlgm+ykr//nPW5w9G4umaWiaRorfLeT41CYkYxtm+0UURWHmzDeBihf7tZDYPUNi\n95zKHH9JYw8Pd9+tq88884zrBxWhss17X2Rz9Pbt27nzzjvp1auXXj3fs2cPgwcP5tVXXy23AG9k\n58+f1ZcdqpkcYw0M9nTMjkRUVZVOWUIIryRTGQKvv/46L7/8MmfPnmXBggXUqlWLjz/+mJEjRzJm\nzJjyjPGGlJaWBlxudsn2iQDFQID1NGolPqCEEEKUXJFJ2GQyce+99wJw1113Ub9+fVavXk2dOnXK\nLbgb2ZtvztSvBaMoZPnURdFs+Nvi9AQ8bdpsT4cphBDlzpsqIEUmYYPBoC/7+vry/vvvExAQUC5B\neRNFUchRw7Gr/vhbT2NQ7IDUgoUQ3subvv+KTMIF34TAwEBJwGVo0aL/Fnp/M32cUxNabGf0WvCL\nL8q9wUII7yRJGDh79iyTJk26YjmfdM4qvVOnTujLdtWfHDUckz0ZMxlwKQmbTCYPRiiEEJ4jSRiY\nOHGiviz3CZe9/IMsw1AbFIVAe6xeFh5ezZOhCSGER0kSBvr371+ecXiNmTOjL68oCpmGWqiaFX8t\nXm+KfuqpcZ4LUAghPMybknCJxo4WZUsfolKpil3xJcBxHsOl2ZK86eATQghv53IWJVF27HY7UKAp\nWq0FQKB2Ti+TJCyE8Haq6j31w2JfaVxcHFlZWfp6VlYWsbGxbg/qRjV79uUezw7FRJYSjo+WgZkM\nvRY8efJ0D0YohBCe500jZhWbhNetW8f8+fP19ffff5+1a9e6PagbWf6Bkq5UA0UlSDuvj5DlTWd/\nQghRFEnClwwYMIAff/yR3Nxc8vLy+P777xk8eHB5xXbDcibhmqA5COSCfvCMHv2sp0MTQgiP86Yk\nXOw1YYvFwj333MPKlStRVZWuXbvKoB2lNGfO9MvjRGsB5CmBBGgX8VFsgLM8LCzMgxEKIUTFUBmT\naWm57Jj10EMP8eyzz6KqKu+88055xHTDUlUVh8NBOjUACFbOoyAdsoQQoiBv+j50mYQjIiKoVasW\nBoOB2rVrl3jHDoeDqVOncuTIEUwmE9OnT6devXr69n379jFr1iw0TSM8PJzZs2djNptL9yoquC++\n+LTAmkI64RiwYiFFP9juvbenZ4ITQgjhMSW6Ralg56ySWrt2LXl5eSxZsoSYmBhmzZrFggULANA0\njSlTpvDOO+9Qr149li5dSlxcHA0bNrzmv1MZXLhwVk+2WUowds1EiHIOg6qQ3xR9663tPRihEEJU\nHFITLgO7du2iU6dOALRt25b9+/fr206cOEFISAgLFy7kzz//pHPnzjdsAs6Xf1Cla+EABKsX5d5g\nIYS4Cm/6TnRbEs7IyMBisejrBoMBm82G0WgkOTmZPXv2EB0dTd26dRk7diytWrWiY8eORe6vShV/\njEZDkdtLKjw88Lr3cS0mT56sLzs0hTStKj7kEqBk6AfatGnT8PHxcbmv8o69LEnsniGxe05ljt/T\nsUsSLiAhIYHw8PBr3rHFYiEzM1NfdzgcGI3OPxcSEkK9evVo1KgRAJ06dWL//v3FJuHk5Kwit5VU\neHggCQnp172fa6WPkEUIDoyEqvGo6uWDLCUlB8gpdh+eir0sSOyeIbF7TmWOv6SxuzNRe1MSdjk6\nxEMPPcTo0aNZs2YNVqu1xDuOjIxk8+bNAMTExNC0aVN9W0REBJmZmZw6dQqAnTt30qRJk2uNvcJb\nv/4nfVlRFFIdzpOZEEOifk9bt249PBWeEEJUSHKfcAE//vgjO3fuZPny5cyZM4fOnTvTv39/Wrdu\nXezzoqKi2LJlC8OGDUPTNGbOnMmqVavIyspi6NChzJgxg/Hjx6NpGrfccgtdunQpq9dUYRw4sFc/\nKGwOlXRHCGYlCz81Wy9v2/YWT4YohBAVjjeNHliia8Lt2rWjdevWrFmzhrlz57J+/XpCQ0OJjo6m\nbdu2V32Oqqq88sorhcrym58BOnbsyLJly64j9MolzVEFDZUQQ2KhpmghhBDey2US3rp1K99++y1b\nt26lc+fOzJ07l8jISI4cOcITTzyhNzmLwpYs+axQ00iKvSoAVQzJgLO55dln/+2R2IQQoiKrjM3K\npeUyCc+fP5+BAwcydepU/Pz89PJmzZrx6KOPujW4yiwp6aK+bMdIhiMQPyUTX0MeiuI9TS1CCHGt\nJAkXcPfddzNgwIBCZW+++Sbjxo3jkUcecVdcN4T8AynNFuJsijam6J0HgoOreDg6IYSomNyVhF2N\n5Lhw4UKWLl1KaGgoAC+//DINGzakf//++i23derU4dVXX+XgwYOMGTOG+vXrAzB8+HB69uzJpk2b\nmD9/Ppqm0bJlS1566aViX0+RSXjOnDkkJiayfv16Tp48qZfbbDb27dvHuHHjrue9uKH9+utmfWpC\nh8NBij0EgCo+l5PwyJGPeThKIYSomNyVhIsbyRFg//79vPbaa7Rq1Uovy83NRdM0Pvvss0L7OnDg\nAP/4xz8KtQhnZGQwe/ZsFi1aRGhoKB9++CHJycl6Ur+aIpPwfffdx/Hjx/ntt9/o0KGDXm4wGHjq\nqaeu7ZV7mYMHY/RlTTGSZgvCV83Gz5CHql7/gCNCCHEjc1cSLm4kR3Am1g8++ICEhAS6dOnCmDFj\nOHz4MNnZ2Tz66KPYbDbGjRunP/fEiROsW7eOevXq8cILL7Bnzx6aNm3Ka6+9xpkzZxg8eHCxCRiK\nScJt2rShTZs2REVFFRr5SpRM/kGUag1CQyXUJxVVVSvtvWxCCFFe3PUdWdxIjgC9evVixIgRWCwW\nnn76aTZs2ECtWrV47LHHGDx4MCdPnuSJJ57ghx9+oE2bNgwePJhWrVqxYMEC5s+fT4sWLdi+fTsr\nVqzA39+fBx98kLZt29KgQYMiYyqyh1D//v0B5+1JLVq00H+aN29OixYtyuo9uSEVvHE82RoMQKgp\nTS8bM+afHo5QCCG8T3EjOWqaxsMPP0xoaCgmk4nOnTtz8OBBGjRowAMPPICiKDRo0ICQkBASEhKI\niorSm62joqI4ePAgISEhtG7dmvDwcAICAmjXrh2HDh0qNqYik/Dy5csBOHz4MIcOHdJ/8teFaxoq\nKdZAzGou/oZcqQULIUQJuGvErOJGcszIyKB3795kZmaiaRrbt2+nVatWLFu2jFmzZgFw4cIFMjIy\nCA8P57HHHmPfvn0AbNu2jZYtW9KyZUuOHj1KUlISNpuNvXv30rhx42JjKrI5et68ecU+8emnny52\nu7f6/PNPCjRFB+LAQKgpCVWVBCyEECXhru9KVyM5Pvfcc4waNQqTyUTHjh3p3LkzeXl5TJo0ieHD\nh6MoCjNnzsRoNDJ16lR98p2wsDCmTZuGxWJh/PjxPP744wB07969UKK/GrfNouSt8vJy9AMoKS8I\ngKqm9Eo9tqkQQpQnd31PuhrJsV+/fvTr16/QdpPJxBtvvHHFvlq2bMnixYuvKO/Vqxe9evUqcUxF\nJmGp6V4vheQ8Cz6qlUCfHD0BN2vW0tOBCSFEhSZjR+PsmLV8+XKaN29e6KxE0zQURZHrwlfx2Wcf\nAs6zuHSbHzbNSHVzsj5WtKIo3HVXFw9GKIQQFZ83tRgWmYQLdswSJac3Rec6u8GHmjP1Mm86sIQQ\norS86bvS5TVhq9XK4sWL+f333zEajdxxxx0MGjTIq96kkoiLiwPQR8lKyrOg4qCKOUt/r2SgDiGE\nEAW5TMKvvPIKGRkZ9O/fH03TWLFiBUeOHGHy5MnlEV+lsXHjD/pyrsNEls1MqDkDowrgvB788MOj\nPRafEEJUFt5UyXOZhGNiYli1apW+3rVrV/r27evWoCqr/AMnMTcAgKq+WXoHA286qIQQ4np40/el\nyy5o1atX58yZM/p6fHw84eHhbg2qsvnzz6P6sqIoJOY4k3CYX5beK/rBB2XCBiGEKAl3DdZRERVZ\nEx45cqRz2MXkZB544AHat2+Pqqrs3r2bJk2alGeMFd6uXVv1f77VDim5flh8cvEzOshvivamLvdC\nCHE9KmMyLa0ik/Azzzxz1fKC0zaJwhRFITnXDw1FrwXnlwshhCgZb/rOLDIJF5y+8ODBg2RlZaFp\nGna7ndjY2ELbhfOg0TSNxBx/AML9svUDacQIOXERQoiSkiRcwIQJE9izZw+pqak0bNiQw4cPExkZ\nyaBBg8ojvgpv6dLP9ANG0yAxxw8f1U6w2Vppr1EIIYQoHy4vVO7YsYPvvvuO+++/n2nTpvHVV1+R\nl5dXHrFVKoqikGUzkWs3UtUvR5+wQZKwEEJcG2/qmOUyCVerVg0fHx8aNWrEkSNHaNKkSaH5GEWB\nW5NyfAEI87s8VnTbtrd6MjQhhKh0VFUt9U9l47I5unr16rz//vt07NiR2bNnA5CVleX2wCqDxMRE\nfYQsgIvZfgCE+efqiblZs1Yei08IISqjylijLS2Xpw0zZsygTp06tGnThvvvv5/Vq1czderUcgit\n4tu8+Sf99iOHppCcYybQZMXPxznJhcEgw1QKIcS18qbmaJc1YYvFwu2338769eupW7cuvXv3JiQk\npDxiq/Dye0QDpOT64tAUwv1zZZQsIYS4Dt703emyJrxmzRr69u3LihUr+Oqrr+jXrx+bN28uj9gq\nhfyzr4Qs5/Xg8IA8vax//+Eejk4IISofuSZcwIIFC/jmm2+oVq0a4Jwt6Mknn+Tuu+92e3AV2a5d\nvxe6HpyQZUZVNKr6W2WQDiGEECXiMgkbjcZCY0XXrl0bo9Hl0254586d1pdzbAYy8oxUC8jFoCLD\nVAohxHXwpgpMkdl0xYoVANSpU4exY8fSr18/jEYjq1evplmzZuUWYEWWn2wvZpkBqGaxoqoqiqLg\n4+Pr4eiEEKJykiQMbN++HYCAgAACAgL068D+/v7lE1kFdvZsXKGDJCHTBEB1y+VRsnr0eMBT4Qkh\nRKUmSRh49dVX9WWr1cqJEyew2+00adLE65uj9+3bUWBNISHLB7PRQaDZIc3QQghxnSQJF7B//36e\nffZZQkJCcDgcXLx4kfnz53PzzTeXR3wVVv5Bkp6rkmtTiQjO1YeqFEIIUXreVJlxmYSnT5/O3Llz\n9aQbExPDtGnTWLZsmduDq6j0ATocDhIyfQAIt9j0puh77+3t4QiFEKLy8qbKjMsknJWVVajW27Zt\nW3Jzc90aVEX2yy/r9GVVVUnIdL6F1Sx2fYQsk8nkkdiEEEJULi7r/MHBwaxdu1ZfX7t2rVePmJWX\nl1NgeDSFhAwj/j4OAn2ptMOmCSFEReKuYSsdDgfR0dEMHTqUkSNHcurUqas+bsqUKcyZM6dQWWJi\nIp07d+b48eOFyletWsXQoUP19enTpzNgwABGjhzJyJEjSU9PLzYmlzXhadOm8fzzz/Piiy8CEBER\noU/k4K3y/9HJWQp5dpVawVb9enBISJiHoxNCiMrNXZWZtWvXkpeXx5IlS4iJiWHWrFksWLCg0GMW\nL17M0aNHad++vV5mtVqJjo7G17fwracHDx5k2bJl+vDFAAcOHOC///0voaGhJYrJZU1427ZtLF26\nlA0bNrBu3TqWLVtGgwYNSrTzG01s7MlCo2ElZDjPYaoH2vWzsA4d7vBkiEIIUem5a9jKXbt20alT\nJ8B5aXX//v2Ftu/evZu9e/cWqtkCvPbaawwbNkwfORIgOTmZN998kxdeeEEvczgcnDp1iujoaIYN\nG1aivlMuk/Dnn38OOO8PtlgsLnd4Izt27DBw+QCJz3BeA64e5JBRsoQQooy4qzk6IyOjUB4zGAzY\nbDYA4uPjmT9/PtHR0YWe88033xAaGqonbwC73c6LL77IpEmTCAgI0MuzsrJ46KGHmD17Nv/973/5\n4osvOHz4cLExuWyOrlGjBqNGjeLmm2/GbDbr5U8//bSrp96Q8v/JdodGfIaBQLODQF/n9WFJwkII\ncf3c1RxtsVjIzMzU1x0Ohz7uxQ8//EBycjKjR48mISGBnJwcGjZsyNdff42iKGzbto1Dhw4xYcIE\nJkyYwKlTp5g6dSq5ubkcO3aMGTNmMHHiREaNGoWfn3Nu+dtvv53Dhw/TvHnzImNymYTbtm17va/7\nhpE/daGiKCRnKVjtCvVCLzdFd+3aw9MhCiFEpeeuJBwZGcmGDRvo2bMnMTExNG3aVN82atQoRo0a\nBThrv3/99RcDBgxgwIAB+mNGjhzJ1KlTadSoEd999x0AsbGxjBs3jhdffJHjx4/z//7f/2PFihU4\nHA52795N//79i42p2CSclJREly5daNSokZ7ZvVX+2VN+Io5PdzZF1wjWpFe0EEJUAlFRUWzZsoVh\nw4ahaRozZ85k1apVZGVlXXEduDQaNWpE3759GTJkCD4+PvTt25cmTZoU+5wik/CaNWt44YUX8Pf3\nx+Fw8Pbbb9OhQ4frDrKyion5rdDUhRfSnU3PNYIkCQshRFly1/epqqq88sorhcoaNWp0xeMK1n4L\n+uyzz64oq1OnDl999ZW+/vjjj/P444+XOKYik/CCBQtYtmwZjRo14pdffuHdd9+9agDeRlVV7HYH\nCekKgWaNALOilwshhLh+3vR9WuQrVRRFP0Po1KkTKSkp5RZURZV/dpaao5JnV6gerOk9pdu37+Ti\n2UIIIUrCXb2jK6Iia8J/PxO51pmTHA4HU6dO5ciRI5hMJqZPn069evWueNyUKVMIDg7mX//61zXt\nv7wV/OfGXxoApUbQ5YPl7zdxCyGEKJ3KmExLq8jMmpmZyc6dO/WRQLKysgqtFxxN5GpKOzJJRfT7\n75sLXw9Oc5ZXD1ZQFO86YIQQwt286Tu1yCRcvXp13n77bX29WrVq+rqiKCxatKjYHV/LyCR//fVX\nqV9AeSk4c9KFNPD1gRB/ZxL2pusXQgghyk6RSfh6O2EVNTKJ0WjURyaZN28ea9asKdH+qlTxx2g0\nXFdMAOHhgdf1/Mw8hcxcjfphYDA4k29gYOB177ckyuNvuIvE7hkSu+dU5vg9Hbs3VWyu7ULvNSjN\nyCRFdQsHSE7Ouu6YwsMDSUgofkaLqynYNHIh1dkcXzP4cieAli1vLdV+r0VpY68IJHbPkNg9pzLH\nX9LY3ZmopTm6DJRmZJKKKH+ErHznL10PrllFrbS98YQQoiLzpu9VtyVhd49MUl727t2uLyuKwrkU\nDaMKYYGVt0u8EEJUZN70veoyCaempjJ79mxOnz7N22+/zeuvv87EiRMJDg4u9nnXOzJJRZLfISvH\nqpGcCXVCFYyXrgd707ULIYQoD96UhF1mkClTptC6dWtSUlIICAigWrVqPP/88+URW4WR3zP6Qqpz\nvWbI5bkrIyKKHxdUCCHEtXHXfMIVkcuIY2NjGTp0KKqqYjKZeO655zh//nx5xOZx+deD83/OXeqU\nVSvUoJeFh4d7OEohhBCVlcvmaIPBQHp6ut48cPLkyUp5tlEaBw7s0pcVReFCinOwjhrB0ilLCCHc\nxZu+W10m4WeeeYaRI0dy7tw5/u///o+YmBhmzpxZHrFVCPnXgx0OjQtpDqpaFMw+qt5ELYQQomxJ\nEi7gzjvvpFWrVuzbtw+73c4rr7xCWFhYecRWIeQn24vpdmx2qBFiwGBwDhpStWpND0cnhBA3HknC\nBXTp0oWoqCgeeOAB2rZtWx4xVRiKoujXhc+l2AGoVcWgHyC1atXxZHhCCHFD8qZWRpevdPXq1bRo\n0YK5c+fSvXt33n33XU6dOlUesVUo5y9dD64Z6rZbq4UQQuBdUxm6TMLBwcEMHjyYTz/9lNmzZ7Nh\nwwZ69OhRHrF51OHDMYV7RifbMRmhqkWuBwshhCgbLqt1SUlJrFmzhu+//57U1FR69+7NvHnzyiM2\njyp4VpWd5yA500HdMCOqKj2jhRBClA2XSbhv37706NGDSZMm0apVq/KIqcLIT7Tn868HF7g/2Gwu\nfnKGFN8AACAASURBVMQwIYQQpeNNlRyXSXjTpk1e2fRaqFNWcn6nLB89CTds2NDDEQohxI1JkjDQ\nv39/li9fzk033VToDclPTIcOHSqXAD0p/3XrSTjUKE3RQgjhZt70HVtkEl6+fDkAhw8fvmJbXl6e\n+yKqABITE/WDwOFwcDbZRpUAlQBfg1cdHEII4Qne9D3rsp3579MOOhwOBg4c6LaAKoKUFOfY2Iqi\nkJzpINeqUSvUp1J3gxdCiMrCm25RKrImPGrUKH7//XcAmjdvfvkJRiPdunVzf2QVxNkkZ1N07ao+\n+j+4Mv6jhRCisvCm79gik/CiRYsAmD59OpMnTy63gCqC/DMqTdM4l2wFoGYVo76tYcObPBmeEEKI\nG4TL3tHPP/88P//8M5mZmQDY7XZiY2P55z//6fbgPEm/PSnZhqpA9ZDLzdHe2FtcCCHKi7tqwg6H\ng6lTp3LkyBFMJhPTp0+nXr16+vYff/yRDz74AEVR6NOnDw8//DB2u53Jkydz4sQJFEXh5ZdfpmnT\nphw7dowpU6agaRr169dn+vTpGI1G/e+MHj2ae+65h+HDhxcbU4lmUcrOzub06dO0a9eOHTt23NBj\nSJ86dUQ/AOwOjQupNqoFG/ExOhOvNzWTCCHEjWTt2rXk5eWxZMkSYmJimDVrFgsWLACcFcw33niD\nr7/+Gn9/f3r27EmfPn3YvXs3AIsXL2b79u3MnTuXBQsW8OabbzJu3Djat2/PxIkT2bBhA1FRUQC8\n9dZbpKWllSgml1W6EydOsGjRIqKionj88cdZunQp8fHxpX0PKg1FUbiYZsfugJrSKUsIIcqNuzpm\n7dq1i06dOgHQtm1b9u/fr28zGAx8//33BAYGkpKSgsPhwGQyce+99zJt2jQAzp49S1BQEADvvvsu\n7du3Jy8vj4SEBCwWCwA//PADiqLof8cVl0m4atWqKIpCgwYNOHLkCNWrV7+hb1Eq+I88n2wDoFao\nSS8PCKjqyfCEEOKG564knJGRoSdLcCZem82mrxuNRn766Sf69u1Lhw4d8PPz08snTJjAtGnT6NOn\nj/7cuLg4evfuTXJyMs2bN+fo0aOsXr36mi7XukzCTZo0Ydq0adx2220sXLiQDz74AKvVWuI/UBnp\nkzakOF9nwduTqlWr5uHohBDixuauJGyxWPT+TeC8dpt/HTfffffdx+bNm7FaraxYsUIvf+211/jx\nxx+ZMmUKWVlZANT+/+3de1xUZf4H8M8MwwCChCNggJcVFVzTREPS9afmhRd5AQIyREB8gZu6IXmX\n3DQSRdhKW1kp7bIkmpfMRI1cS3QtCiMN79qmSIiE3JHrwMzz+wPnMOMAo8TMmeF836+XL2fOOXP4\nnjPDfHme85zv4+KCEydOICQkBImJiTh8+DCKi4sRERGBL774AqmpqThz5kyHMelMwnFxcZg+fToG\nDx6MmJgY3Lt3D++8846ul5mkoqIiAGpJuLwJZmKgj52UBmQRQoiB6CsJjx49mkuKubm5cHNz49bV\n1NQgLCwMcrkcYrEYVlZWEIvFOHz4MHbs2AEAsLKy4nLBokWLcPv2bQCAtbU1xGIxVq9ejc8++wxp\naWkICAjA/PnzMXHixA5jandgVk5Ojtbznj17wsfHB1VVVR3u1FQpFK1/ISmUQHFlE/rYmUMioeRL\nCCGmztvbG1lZWZgzZw4YY0hISMDRo0dRV1eH4OBg+Pr6IjQ0FBKJBO7u7vDz80NjYyNee+01hIaG\norm5GWvXroWlpSVefvllxMbGwtzcHFZWVti4cWOnYhIxxlhbK8LDw9t/kUjE3UdsKCUl9//wPhwc\nena4n8LCm1AqlWCM4W65HDuP34PnYGvM8uoFoOW4+/Ub8ofj6AxdsRszip0fFDt/TDn+R43dwaGn\n3mJ4uBH4OMaMGdOFkehfuy3htLQ0Q8ZhNLhJG8ofXA/uLeWW9erlxFtchBAiFEK6C0XnfcLh4eFt\nnhBDt4QNQf0475a3jADva2/BXWtQH1VHCCFEPygJq1myZAn3uLm5GSdPnuTuk+pO5HK5xhtfVN4E\niZkIjnbSR7rgTwghhDwunUnYy8tL4/lf/vIXzJ49u9uVrayoKOIeNysZiivlcJJJITGjSlmEEGJI\nQvq+1ZmE7969yz1mjOHXX39FZWWlXoPig3pr915lMxRKwKW3Bc2cRAghBiak71udSTgsLIx7LBKJ\nIJPJuu2sSqo3/m5Zy/Vg9SQsFlvyFhchhJDuSWcSzszMNEQcRoEbGV3xIAnbtyZhR8cneYuLEEKE\nhFrCam7duoUDBw5oFejYvHmz3oLig2r+4JZKWY0wEwOOdhaC+jAQQogxENL3rs4kHB0djRkzZsDd\n3d0Q8fCirKyQe6xUMvxeLoejnZSmLySEEB4I6TtXZxK2tbVFdHS0IWLhjfqgrLL7TWhSMDjJaFAW\nIYTwQUjfuTqTcEBAALZu3YqxY8dqzDZhaqXBdGmtlNVyPdhZY1AW1Y4mhBBDoSSs5scff8SlS5dw\n/vx5bhkftaP1SfN6cAMAwKW3JfdBkMmc+QyPEEIEhZKwmsuXL+PEiROGiIVXD9+e5GxvKagPAiGE\nEMPT2c/q5uaG69evGyIWXlRXV2vMRXm3rAF2NhJYW0qoXCUhhBC90tkSLigoQEBAABwcHGBubs51\n2548edIQ8RlAS/ezSCRCVW0T7tcr8NQAG0rAhBDCEyF99+pMwtu3bzdEHLxSXRMuKm8EALiodUUL\n6cNACCHGQEjfuzqTcHuTK7u4uHR5MHwSiUS4W9rSKna2t+SWiURWfIZFCCGCQ0lYzdmzZ7nHTU1N\nOHfuHDw9PfHCCy/oNTBDah2UpWoJW3Hd0d1x2kZCCDFmlITVPFyesrKyEsuWLdNbQIam6ooGgMKy\nBlhKxehtKxXUh4AQQoyJkL5/H7sKRY8ePVBYWKh7QxOhavHKm5S4V9kI596WENP1YEIIIQagsyUc\nHh7OJSPGGO7cuYNJkybpPTBDqKsrB9CSbH+vaARjQN8HXdGq5YQQQgxLSN+9OpPwkiVLuMcikQi9\nevXC4MGDde5YqVQiLi4ON27cgFQqxcaNGzFgwABu/bFjx/DJJ5/AzMwMbm5uiIuL46U8pKo7+m7Z\ng0pZDpSECSGEGEaHWa+qqgqDBw+Gl5cXvLy8wBiDTCZ7pB1/8803kMvl2L9/P1asWIHExERuXUND\nA959913s2rUL+/btQ01NDU6dOvXHjqQT1JNtURuDsigJE0KI4al/Bz/uP1PTbhK+evUqZs6cicuX\nL3PLsrKy4O/v/0gVtM6dO4cJEyYAADw8PDT2I5VKsW/fPlhZtdz+09zcDAsLi04fxB/BjYx+UDP6\nSZkFt7xHj0f7g4MQQkjXEVISbrc7OikpCe+88w6effZZbtmyZcvg6emJxMREpKamdrjjmpoa2NjY\ncM/NzMzQ3NwMiUQCsVgMe3t7AEBaWhrq6uowfvz4DvfXq1cPSCRmj3JMHXJw6Mk9/u23itbZk8oa\nYG8rhaW05ZSIRCKNbY2BscXzOCh2flDs/DHl+E05dlPTbhKurq7WSMAqEyZMwNtvv61zxzY2Nqit\nreWeK5VKjakQlUol3nrrLeTl5SE5OVnnXzAVFXU6f6YuDg49UVJyHwAgl1dz14Nr6ptRU9+MgU5P\naMSh2tYYqMduaih2flDs/DHl+B81dn0man21aDszVkmhUGDt2rUoLCyEXC7H4sWLMXXqVFy7dg3x\n8fEwMzODVCpFUlIS7O3tsWfPHhw6dAgikQiRkZGYMWNGhzG12x3d3NwMpVLZ5kE0NTXpPNjRo0fj\nzJkzAIDc3Fy4ublprF+/fj0aGxuRkpLCdUvzRTUoy7m3JbfMFLs1CCGEtK8zY5WOHDkCOzs7fPrp\np/jwww8RHx8PANi0aRPWrVuHtLQ0eHt744MPPkB5eTn27t2Lffv2ITU1FUlJSVwdiva02xIeM2YM\n/vWvfyEmJkZjeUpKCoYPH67zYL29vZGVlYU5c+aAMYaEhAQcPXoUdXV1GD58OA4ePAhPT09EREQA\nAObNmwdvb2+d++1KrZWyHoyMVrs9iY+R2oQQQvTXCOrMWKXnn38ePj4+AFpu0zUza7ksumXLFjg6\nOgIAFAoFLCwsIJPJcPjwYUgkEhQWFsLCwkLnsbSbhJcvX46XX34ZR48exYgRI8AYw9WrVyGTyfDe\ne+/pPFixWIwNGzZoLBs0aBD32BimR1S/HgwAzvY91C7u8zNQjBBChE5fSbgzY5VUsdTU1CAmJgZL\nly4FAC4Bnz9/Hrt378aePXsAABKJBLt370ZycjLCw8N1xtRuEraxscGePXuQnZ2Na9euQSwWIzQ0\nFJ6enp08fOOiuh7cModwPcRiEZ6Utc6eJJVSEiaEkO6ks2OVioqK8Morr2Du3Lnw9fXlts/IyMB7\n772HnTt3aty+GxYWhpdeegl//etfkZ2djbFjx7YbU4fFOkQiEcaNG4dx48Y9/tEaOdXJVSqVuFta\njyd7WUBiJtZYRwghxPD09R08evRonDp1CjNmzGh3rJJUKkVKSgp3SbK0tBSRkZFYv369Ri5MT0/H\n/v37kZaWBjs7OwDArVu3sGXLFiQnJ8Pc3BxSqVTnpU2dFbO6I6WydaR1RU0TGpuUXFc0QEmYEEL4\npK/v4M6MVTp79iyqq6uRkpKClJQUAMCOHTuwadMmODk5cVUlx4wZg5iYGAwdOhTBwcEQiUSYMGEC\nvLy8Oj5WpmvolpHoiuH+qqH3SmUdGGNgjOHizQr864v/wf//+mLmWGcALR8AMzPrP/zzupIQbnkw\nRhQ7P0w5dsC04zeGW5R+++23Tr+2f//+XRiJ/gmyJazScj1Ye2Q0IYQQYgiCTMLqs0IVlrR0TbvY\n9+DW0+1JhBDCHyE1iASZhFVEIhEKS+shlYhhb2ehdk2Y3+IhhBAiZJSEBUAkEkGhZPi9vB59HXrA\nTCwW1BtPCCHGSkjfxQLsd5Vzb3BxeT2aFQwuDjQymhBCiOEJsiXcWq6yHkDr9eCW5ZSECSGET0Jq\nDAkuCYtEauUqSx8kYYfWcpWMCefNJ4QQYySkJCzA7ujWbueiBy1h597qNaOF8+YTQgjhl+BawmKx\niJta6m5ZPaTmYvS2s1T7y8ucv+AIIYRQS7g7U3VHMwb8Xl4PJ5kVxA9awUJ64wkhhPBPUC3hqqoq\nAC1JuKy6AU3NSo3pC02jgCchhHRvQmoQCSoJA61TGHLXg9UmbiCEEMI/IX0nC647GnhQM7q0pVyl\ns9rtSQqFIE8HIYQQngiqJaz+11VrEramkdGEEGJEqCUsAHdL6yAWAU4a3dHCeeMJIYTwT1AtYaDl\nLyylUom7pXVwlFlBYqb6O4QSMCGEGAMhtYQFlYRVg7Lu1zWjtqEZQwfYqU1ryHNwhBBCAAgrCQum\nO9r8QQ2OlukLawG0DsoCAKVSOG86IYQQ4yCYlrBY7c+N1prR1txfXM3NfERFCCHkYUJqCQsmCbdW\nymJcS9jFwfrBOhEA6o8mhBBjIKQkLJjuaPX5gh++PYkQQgjhg6CSsCrhFpbUQmZrgR6WgukIIIQQ\nYoQEl4Ua5AqUVzdihKtMbWQ0dUUTQoixEFIPpWCSsOp68N2HrgcTQggxLkJKwoLojrayar0erBoZ\n7ezQWq5SoaCWMCGEEMMTRBJWvx5cVNbSEnZSu0dYLuclLEIIIW1QfWd35l9HlEol1q9fj+DgYISH\nhyM/P19rm/r6esyZMwc3b97UWH7hwgWEh4drbZ+QkIC9e/dyz/fs2YOgoCC8+OKLyMjI0HmsgknC\nqv9VUxi6aEzcQAghpLv75ptvIJfLsX//fqxYsQKJiYka6y9duoTQ0FAUFBRoLP/ggw/w+uuvo7Gx\nkVtWXl6OBQsWIDMzU2PZ3r17sW/fPqSmpiIpKUnnmCNBJGGxWqWOorJamEvEkNlaAhDWtQdCCDEF\n+moJnzt3DhMmTAAAeHh44PLlyxrr5XI5tm/fDldXV43l/fv3R3Jyssay2tpaLFmyBP7+/twymUyG\nw4cPw9zcHKWlpbCwsNAZkyCSMNCabItK6+DUuwfMzMTcYC1CCCHdX01NDWxsbLjnZmZmaFYrl/jM\nM8/AyclJ63U+Pj6QSDTHMffr1w8jR47U2lYikWD37t0IDg6Gn5+fzpi6fRJWL1dZeV+OBrkCTvY0\nMpoQQoTGxsYGtbW13HOlUqmVXLtCWFgYvv32W+Tk5CA7O7vDbbt9Era0NONawXdVg7J6tw7KUigU\nvMRFCCGkbfrqjh49ejTOnDkDAMjNzYWbm1uXxn3r1i1ER0eDMQZzc3NIpVKNy6Ft6fb3CZs9mC9Y\nJBLh9zLtcpX19dQdTQghQuDt7Y2srCzMmTMHjDEkJCTg6NGjqKurQ3Bw8B/ev6urK4YOHYrg4GCI\nRCJMmDABXl5eHb5GxEzkomhJyf1Ovc7WVso9TvvqBtK/zcPGhc9i6IBeAIDqatO4P8nBoWenzwHf\nKHZ+UOz8MeX4HzV2B4eeeotBvcv4cVlbm9blxm7fElbvnlBVy3LqTRM3EEII4Z8gkrCqsV9UVgtr\nSwmesJHqeBUhhBC+CKmR1O0HZgEtb6iSAb+X1cGJinQQQggxEt0+CauSbWllPZoVjOYQJoQQYjS6\ndXe0alCWSCTirgc7P7hHWCQSQalU8hYbIYSQtgmpodStW8Ia5SpVSdjBhnuDa2tNY2Q0IYSQ7qlb\nt4TVr/1yLWGH1pYw1ekghBDjQy3hbkL9jSwqbSnU4WJvI6g3mBBCiPHq9klYvSXcq6cFrCwl3DpC\nCCGET3pLwromT87MzERQUBCCg4Nx4MABvcSgSrTNCiXuVdTB2YFuTyKEEGI89HZNWH3y5NzcXCQm\nJuK9994DADQ1NWHz5s04ePAgrKysEBISgilTpsDe3r7L4xCJRCgqqwNjgLN96xRWJlKtkxBCBEdI\nDSW9JeGOJk++efMm+vfvjyeeeAJAyxyOOTk5mD59erv769WrByQSs8eKQZVorS3N8YS1FKPcHbk3\nVywW67X2qT6YWrzqKHZ+UOz8MeX4TTl2U6O3JNze5MkSiQQ1NTXo2bP1Tba2tkZNTU2H+6uoqHvs\nGHo/qBFtb2eFXXE+Gn9dmVpxdSEUhDdGFDs/TDl2wLTjN4YJHITUEtbbNeGOJk9+eF1tba1GUu4q\nDQ0t9wGLRCKIxWLujVUoqEgHIYQQ/uktCXc0efKgQYOQn5+PyspKyOVy/PTTTxg1alSXx1Bb24Sq\nqnooFAqua1oub+pUq5oQQohhqAbQduafqdFbd7SuyZNjY2MRFRUFxhiCgoLQp08fvcTR1KRAeXlL\n0nVw6Inq6ka9/BxCCCHkcektCYvFYmzYsEFj2aBBg7jHU6ZMwZQpU/T14wkhhBCj163LVhJCCDE9\nptit3FndumIWIYQQYsyoJUwIIcSoUEuYEEIIIXpHLWFCCCFGhVrChBBCCNE7SsKEEEIIT6g7mhBC\niFERUnc0JWFCCCGCoFQqERcXhxs3bkAqlWLjxo0YMGAAtz4zMxPbt2+HRCJBUFAQXnrppXZfk5+f\nj9jYWIhEIgwZMgRvvPEGxGIxUlNT8eWXXwIAJk2ahOjo6A5jou5oQgghRkVftaPV57lfsWIFEhMT\nuXWqee4//vhjpKWlYf/+/SgtLW33NZs3b8bSpUvx6aefgjGGkydPoqCgAEeOHMG+fftw4MABfPfd\nd7h+/XqHMVESJoQQIgiPOs+9VCrl5rlv7zVXrlyBl5cXAGDixIn4/vvv8eSTT+LDDz+EmZkZRCIR\nmpubYWFh0WFMJtMd3VVzV5ryZNUUOz8odn6YcuyAacdvyrF3pDPz3Lf3GsYY1/K2trbG/fv3YW5u\nDplMBsYY/vGPf2DYsGEYOHBghzFRS5gQQoggdGae+/ZeIxaLNba1tbUFADQ2NmLlypWora3FG2+8\noTMmSsKEEEIEoTPz3Lf3mmHDhuHs2bMAgDNnzsDT0xOMMfztb3+Du7s7NmzYADMzM50xiZhqtntC\nCCGkG1ONdP7ll1+4ee6vXr3KzXOvGh2tmuc+NDS0zdcMGjQIeXl5WLduHZqamuDq6oqNGzciMzMT\ny5cvh4eHB/czly9fjlGjRrUbEyVhQgghhCfUHU0IIYTwhJIwIYQQwhNKwoQQQghPTOY+4UfVmbJk\nxqKpqQlr165FYWEh5HI5Fi9ejKlTp3LrU1NT8dlnn0EmkwEA3nzzTbi6uvIVrpaAgADufrq+ffti\n8+bN3DpjPu8AcOjQIXzxxRcAWm4xuHbtGrKysrjbDoz13F+4cAFvv/020tLS2i2jp6Lrd4PP2K9d\nu4b4+HiYmZlBKpUiKSkJ9vb2Gtt39PkyNPXYr169ioULF+JPf/oTACAkJAQzZszgtjXm875s2TKU\nlpYCAAoLCzFy5Ehs3bpVY3tjOu/dEutm/vOf/7A1a9Ywxhj7+eef2aJFi7h1crmcTZs2jVVWVrLG\nxkYWGBjISkpK+ApVy8GDB9nGjRsZY4xVVFSwSZMmaaxfsWIFu3TpEg+R6dbQ0MD8/f3bXGfs5/1h\ncXFxbN++fRrLjPHc79y5k82aNYvNnj2bMcbYwoULWXZ2NmOMsXXr1rETJ05obN/R74ahPRx7aGgo\nu3r1KmOMsb1797KEhASN7Tv6fBnaw7EfOHCAffTRR+1ub8znXaWyspL5+fmx4uJijeXGdN67q27X\nHd2ZsmTG4vnnn8err74KAGCMad1jduXKFezcuRMhISHYsWMHHyG26/r166ivr0dkZCTmzZuH3Nxc\nbp2xn3d1ly5dwq+//org4GCN5cZ47vv374/k5GTueVtl9NR19LthaA/HvmXLFvz5z38GACgUCq1S\nfx19vgzt4dgvX76M06dPIzQ0FGvXrkVNTY3G9sZ83lWSk5MRFhYGR0dHjeXGdN67q26XhNsrMaZa\n11ZZMmNhbW0NGxsb1NTUICYmBkuXLtVYP3PmTMTFxeGTTz7BuXPncOrUKZ4i1WZpaYmoqCh89NFH\nePPNN7Fy5UqTOe/qduzYgVdeeUVruTGeex8fH67aD4A2y+ip6+h3w9Aejl315X/+/Hns3r0b8+fP\n19i+o8+XoT0c+9NPP43Vq1djz5496NevH7Zv366xvTGfdwAoKyvDDz/8gMDAQK3tjem8d1fdLgl3\npiyZMSkqKsK8efPg7+8PX19fbjljDBEREZDJZJBKpZg0aRKuXr3KY6SaBg4cCD8/P4hEIgwcOBB2\ndnYoKSkBYBrnHQCqq6uRl5eHsWPHaiw39nOv0l4ZPZWOfjeMQUZGBt544w3s3LmTu/au0tHni2/e\n3t4YPnw49/jhz4axn/fjx49j1qxZbVZ3Mubz3l10uyTcmbJkxqK0tBSRkZFYtWoVXnzxRY11NTU1\nmDVrFmpra8EYw9mzZ7lffGNw8OBBboqv4uJi1NTUwMHBAYDxn3eVnJwcjBs3Tmu5sZ97lbbK6Knr\n6HeDb+np6di9ezfS0tLQr18/rfUdfb74FhUVhYsXLwIAfvjhBzz11FMa6435vAMtMU+cOLHNdcZ8\n3rsL4/lzrIt4e3sjKysLc+bM4UqMHT16lCtLFhsbi6ioKK4sWZ8+ffgOmfP++++juroaKSkpSElJ\nAQDMnj0b9fX1CA4OxrJlyzBv3jxIpVKMGzcOkyZN4jniVi+++CJee+01hISEQCQSISEhAV999ZVJ\nnHeVvLw89O3bl3uu/rkx5nOvsmbNGqxbtw5btmyBq6srfHx8AACrV6/G0qVL2/zdMAYKhQKbNm2C\nk5MTlixZAgAYM2YMYmJiuNjb+nwZS2syLi4O8fHxMDc3h729PeLj4wEY/3lXycvL0/rDxxTOe3dB\nZSsJIYQQnnS77mhCCCHEVFASJoQQQnhCSZgQQgjhCSVhQgghhCeUhAkhhBCeUBImenPnzh0MHz4c\n/v7+XPGRKVOmYNu2bV2y/0OHDiE2NrZL9gW03A88atQoFBcXayz/8ccfERAQ8Mj7uXTpEv7+9793\nuE1sbCwOHTqktbwzx3Ty5Ens2rULAODu7s6dbz8/P0yePBnr16+HQqHAqlWrtEpuMsYwbdo0XL9+\nHUlJSV1ShCQ5ObnN0oiEEG10wxfRK0dHR6Snp3PPi4uL4ePjg5kzZ2LQoEE8RqbNxsYG3t7e+PLL\nLxEZGcktP3z4MIKCgh55PyNGjMCIESP0EaIWuVyODz74AGlpadwy9fOtKjTy3XffITAwEAkJCVi4\ncCG3/ty5c7C1tcXQoUPh6OiImJgY7N692yCxE0KoJUwMrKSkBIwxWFtbo7m5Ga+//jqCg4MxdepU\nLFiwAA0NDbhz5w5eeOEFrFq1CrNmzUJERAQqKysBtCREHx8fBAUF4fTp09x+c3NzMXv2bPj5+SEi\nIgL5+fkAgPDwcCQkJMDX1xfe3t7473//iwULFuC5555DamqqVnxBQUE4duwY97yxsRGnT5/mSohu\n3boVL730Enx8fDBnzhyuhN/YsWMRFRUFf39/ZGVlITw8HEBLKzokJAQBAQGYMmUKvvrqK27fp0+f\nRmBgIHx9fZGRkaEVy8WLF7nXRkZGoqCgQGubI0eOwNPTE+bm5m2e74qKCtTX18POzg5jx45FbW0t\nbty4wa1PT0/nqrPJZDLIZDJkZ2dr7GPz5s346KOPuOcxMTE4ceIEfvnlF4SHhyMoKAiTJ0/mWuPq\n3N3ducfqrfxHOTZCBIGHmZuIQBQUFLCnnnqK+fn5MR8fH+bl5cWioqLYmTNnGGOM/fjjjywuLo4x\nxphCoWBhYWHs+PHjrKCggLm7u7MrV64wxhiLjo5mu3btYr///jsbP348KykpYU1NTSwyMpKtWbOG\nNTY2ssmTJ7MLFy4wxhjLyMhggYGBjDHGwsLC2KZNmxhjjCUnJ7Np06axuro6dufOHebp6akVs1Kp\nZFOnTmU3b95kjDF27NgxtmzZMsYYY7dv32bR0dFMoVAwxhhbtWoVN4Wdm5sbN41gdnY2CwsLAJ6d\nKQAABYNJREFUY4wxtmTJEvbrr78yxhj7/vvv2axZsxhjjK1Zs4YtWLCANTU1ccd179499vnnn3PH\n5OvrywoLCxljjJ05c4ZFRERoxbt48WJ2+vRp7rmbmxvz8/NjM2bMYM8++yybO3cuO3LkCLc+OTmZ\nvf3224yxlmnqxo8fz6qqqrj1n3zyCXe+VK5cucICAgIYY4zdv3+fjR8/njU2NrKNGzey77//njHG\n2G+//cY8PDwYY4xt27aNbdu2jYtH5XGPjRAhoO5ooleq7milUonExETcuHGDmyBhzJgxsLOzw549\ne3Dr1i3cvn0bdXV1AIDevXtj2LBhAIAhQ4agqqoKP//8M0aNGsVN9u7r64vs7Gzcvn0btra2ePrp\npwEA06dPx/r167lZhFR1cZ2dnTFy5EhYWVnBxcUF1dXVWvGKRCIEBATg2LFjiImJQXp6Ojejz4AB\nA7BmzRp89tlnyMvLQ25uLvr378+9duTIkVr7e+utt3Dq1CkcP34cFy5c0CjkHxAQAIlEgj59+sDD\nwwMXLlzg1t2+fRsFBQVYvHgxt6ytmafy8/O1SoCquqNTU1Px+eef47nnntP4mREREVi+fDkyMzMx\nduxYjYkenJ2dkZWVpbG/YcOGQS6XIz8/Hz///DMmT54MqVSK2NhYfPvtt9ixYwdu3LjBvXe6POqx\nESIE1B1NDEIsFmP16tUoKyvDxx9/DKBlQNHKlSthaWmJwMBAjBkzBuxBFVX1+WRFIhE3TZ9SqeSW\nq2rYqi9TYYxBoVAAgEZX7aPUvQ0ICEBGRgZKS0uRl5fHTepw+fJlREVFQalUwsfHB9OmTePiBVqm\nfXvY3LlzcfHiRQwfPhyLFi3SWKc+aw1jTCNOpVKJvn37Ij09Henp6Th06BA+/fRTrf2LxeJ2j2n+\n/PlwdHTEW2+9xS1zcXFB3759cf78eaSnp2td6zY3N+emQ1Tn5+eHjIwMZGRkwM/PDwCwdOlSfP31\n1xg0aBCWLVvWZgyqYwPATYH3qMdGiBBQEiYGI5FIsHr1arz//vsoKSnBDz/8gOnTpyMoKAj29vbI\nycnhEmdbnnnmGVy4cAHFxcVQKpXcdVRXV1dUVlZyM9lkZGTA2dkZdnZ2nYrT2dkZzs7O2LZtG/z9\n/bmklJOTAy8vL4SEhGDw4MHIysrqMN7Kykrcvn0br776KiZNmqS1/ZdffgnGGAoLC3Hp0iWNwVyu\nrq6oqqrCTz/9BAD4/PPPsXLlSq2f0a9fPxQWFrYbg2oU9vXr17llQUFBOHjwIPLz87Wmbbxz5w4G\nDBigtR/Vdev8/HxudqasrCzExMRg2rRpyMnJAQCt89GrVy/873//A2MMmZmZj3VshAgBdUcTg5o4\ncSI8PDzw7rvvYt68eVi5ciWOHz8OqVQKDw8P3Llzp93X2tvb4/XXX8f8+fNhZWWFwYMHAwCkUim2\nbt2K+Ph41NfX44knnsDWrVv/UJyBgYFYvXo1vv76a27ZjBkzEB0dDV9fX5ibm8Pd3b3DeO3s7DB7\n9mzMnDkTNjY28PDwQENDA9dt26NHDwQGBqK5uRkbNmzQmENXKpXin//8JzZt2oTGxkbY2NggKSlJ\n62dMnjwZZ8+ebXdWpyFDhuCFF15AUlIS/v3vfwNomWksPj4eERERWq3es2fPIiwsTGs/Tk5O6NWr\nFzw8PLjXLFmyBHPnzoWtrS0GDhwIFxcXrfOxYsUKLFq0CPb29njmmWdQUVHxyMdGiBDQLEqEmLDG\nxkaEhIRg//797Y6QflRlZWWIjo7G3r17uyg6Qogu1B1NiAmzsLDA4sWLu+Sa6o4dO7B27douiIoQ\n8qioJUwIIYTwhFrChBBCCE8oCRNCCCE8oSRMCCGE8ISSMCGEEMITSsKEEEIIT/4fkCh8oUsVyqcA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1235fa588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality of X_val: \t (1000, 1)\n",
      "dimensionality of Y_val: \t (1000,)\n",
      "dimensionality of x : \t\t (5000, 1)\n",
      "dimensionality of y: \t\t (5000,) \n",
      "\n",
      "1 : TRAIN:  4000 TEST:  1000\n",
      "X_train sample: 4000 Y_train sample: 4000\n",
      "first entry of sample X_test [ 0.00192628] first entry of sample Y_test 0.000831536309495 \n",
      "\n",
      "X_train scaling:\n",
      "mean is:  [ 1.95870737]\n",
      "variance is:  [ 3.78639121]\n",
      "\n",
      "\n",
      "X_test scaling:\n",
      "mean is:  [ 2.01599795]\n",
      "variance is:  [ 4.48533168]\n",
      "\n",
      "\n",
      "MLP created\n",
      "Keras wrapper done\n",
      "RANDOM SEARCH\n",
      "Grid is prepared\n"
     ]
    }
   ],
   "source": [
    "### K-FOLD SIMULATIONS ###\n",
    "\n",
    "best_score = np.empty([n_split,])\n",
    "dict_H_layers = np.empty([n_split,])\n",
    "dict_learn_rate = np.empty([n_split,])\n",
    "dict_neurons = np.empty([n_split,])\n",
    "dict_weight_constraint = np.empty([n_split,])\n",
    "dict_epochs = np.empty([n_split,])\n",
    "dict_batch_size = np.empty([n_split,])\n",
    "all_X_test_scaled = np.empty([n_split,int((observations+1-X_val_size-1)/n_split)])\n",
    "all_predictions = np.empty([n_split,int((observations+1-X_val_size-1)/n_split)])\n",
    "\n",
    "#create dataset\n",
    "x_original = create_dataset()\n",
    "index = np.random.choice(observations+1, X_val_size+1, replace=False)\n",
    "    \n",
    "X_val = x_original[index]\n",
    "#Y_val = y[index]\n",
    "\n",
    "x = np.delete(x_original, index, 0)\n",
    "#y = np.delete(y, index, 0)\n",
    "\n",
    "index_sort = np.argsort(X_val[:,0])\n",
    "X_val = X_val[index_sort]\n",
    "#Y_val = Y_val[index_sort]\n",
    "\n",
    "#print('dimensionality of X_val: \\t', np.shape(X_val))\n",
    "#print('dimensionality of Y_val: \\t', np.shape(Y_val))\n",
    "#print('dimensionality of x : \\t\\t', np.shape(x))\n",
    "#print('dimensionality of y: \\t\\t', np.shape(y), '\\n')\n",
    "\n",
    "kf = KFold(n_splits=n_split, shuffle=True, random_state=None)\n",
    "kf.get_n_splits(x)\n",
    "k = 1\n",
    "\n",
    "print('Simulations')\n",
    "M = 0\n",
    "for train_index, test_index in kf.split(x):\n",
    "    \n",
    "    #y = np.sort(np.array([random.uniform(0,1) for i in range(0,observations+1)]))\n",
    "    #y = np.array([0.95*i/observations+0.05 for i in range(0,observations+1)])\n",
    "    y = create_targetset()\n",
    "    plot_dataset(x_original, y)\n",
    "\n",
    "    #take validation set out\n",
    "\n",
    "    #X_val = x[0:(X_val_size+1)]\n",
    "    #x = x[(X_val_size+1):(observations+1)]\n",
    "    #Y_val = y[0:(X_val_size+1)]\n",
    "    #y = y[(X_val_size+1):(observations+1)]\n",
    "\n",
    "    #index = [random.randint(0,(observations+1)) for i in range(X_val_size+1)]\n",
    "    index = np.random.choice(observations+1, X_val_size+1, replace=False)\n",
    "    \n",
    "    X_val = x_original[index]\n",
    "    Y_val = y[index]\n",
    "\n",
    "    x = np.delete(x_original, index, 0)\n",
    "    y = np.delete(y, index, 0)\n",
    "\n",
    "    index_sort = np.argsort(X_val[:,0])\n",
    "    X_val = X_val[index_sort]\n",
    "    Y_val = Y_val[index_sort]\n",
    "\n",
    "    print('dimensionality of X_val: \\t', np.shape(X_val))\n",
    "    print('dimensionality of Y_val: \\t', np.shape(Y_val))\n",
    "    print('dimensionality of x : \\t\\t', np.shape(x))\n",
    "    print('dimensionality of y: \\t\\t', np.shape(y), '\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create k-fold sets\n",
    "    print(k, ':', 'TRAIN: ', len(train_index), 'TEST: ', len(test_index))\n",
    "    #print('TRAIN: ', train_index, 'TEST: ', test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('X_train sample:', len(X_train), 'Y_train sample:', len(Y_train))\n",
    "    print('first entry of sample X_test', X_test[0], 'first entry of sample Y_test', Y_test[0], '\\n')\n",
    "\n",
    "    print('X_train scaling:')\n",
    "    X_train_scaled = scale(X_train)\n",
    "    print('X_test scaling:')\n",
    "    X_test_scaled = scale(X_test)\n",
    "\n",
    "    MLP = create_model()\n",
    "    print('MLP created')\n",
    "    grid, predictions = train_ANN(search, X_train_scaled, Y_train, X_test_scaled)\n",
    "    plot_cdf(X_train, Y_train, X_test, Y_test, X_train_scaled, X_test_scaled, predictions)\n",
    "    ###\n",
    "\n",
    "    best_score[M] = -grid.best_score_\n",
    "    dict_H_layers[M] = grid.best_params_['H_layers']\n",
    "    dict_learn_rate[M] = grid.best_params_['learn_rate']\n",
    "    dict_neurons[M] = grid.best_params_['neurons']\n",
    "    dict_weight_constraint[M] = grid.best_params_['weight_constraint']\n",
    "    dict_epochs[M] = grid.best_params_['epochs']\n",
    "    dict_batch_size[M] = grid.best_params_['batch_size']\n",
    "    all_predictions[M] = predictions\n",
    "    all_X_test_scaled[M] = X_test_scaled[:,0]\n",
    "    \n",
    "    k += 1\n",
    "    M += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#choose structure for MLP\n",
    "print(\"Best error score: \", np.amin(best_score), \"\\n\")\n",
    "print(\"Chosen structure: \", '{ weight_constraint: ',dict_weight_constraint[np.argmin(best_score)],', neurons: ', dict_neurons[np.argmin(best_score)], ', learn_rate', dict_learn_rate[np.argmin(best_score)], ', epochs: ', dict_epochs[np.argmin(best_score)], ', batch_size', dict_batch_size[np.argmin(best_score)], ', H_layers', dict_H_layers[np.argmin(best_score)],'}' )\n",
    "\n",
    "# fix hyperparameters\n",
    "weight_constraint = int(dict_weight_constraint[np.argmin(best_score)])\n",
    "neurons = int(dict_neurons[np.argmin(best_score)])\n",
    "learn_rate = dict_learn_rate[np.argmin(best_score)]\n",
    "epochs = int(dict_epochs[np.argmin(best_score)])\n",
    "batch_size = int(dict_batch_size[np.argmin(best_score)])\n",
    "H_layers = int(dict_H_layers[np.argmin(best_score)])\n",
    "\n",
    "#run on last test set ONLY (?)\n",
    "model, predictions = run_ANN(X_train_scaled, Y_train, X_test_scaled)\n",
    "plot_est_cdf(X_train, Y_train, X_test, Y_test, X_train_scaled, X_test_scaled, predictions)\n",
    "\n",
    "#retrieve these weights\n",
    "#(map weights MLP to validation set)\n",
    "weights = model.get_weights()\n",
    "print(\"length weights\", len(weights))\n",
    "for i in range(len(weights)):\n",
    "    print(\"layers length: (weight + possible bias)\", weights[i].size)\n",
    "\n",
    "#print(model.get_weights())\n",
    "#print(model.get_config())\n",
    "\n",
    "### CHECK PROCEDURE ON TEST SET ###\n",
    "temp_not_saved, Tpredictions = run_ANN_manually(X_test, X_test_scaled)\n",
    "### WARNING (still small differences)\n",
    "np.in1d(predictions,Tpredictions)\n",
    "diff = predictions[:,0]-Tpredictions\n",
    "print('differences between keras and self-constructed-procedure: \\n', abs(diff))\n",
    "\n",
    "### MAP TESTWEIGHTS ON VALSET ###\n",
    "print('X_val scaling:')\n",
    "X_val_scaled = scale(X_val)\n",
    "temp_saved, predictions = run_ANN_manually(X_val, X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DERIVATIVE H=? ###\n",
    "outcome = derivative_revised()\n",
    "\n",
    "for i in range(N_nodes[t]):\n",
    "    #plt.scatter(X_val_scaled, temp_last[:,0], label=\"scaled fitted set\")\n",
    "    #plt.scatter(X_val_scaled, expon.pdf(X_test,scale=1/lambd), label=\"scaled actual PDF\")\n",
    "    plt.scatter(X_val[:,i], outcome[:,i], label=\"fitted set\")\n",
    "    plt.scatter(X_val[:,i], expon.pdf(X_val[:,i],scale=1/lambd), label=\"actual PDF\")\n",
    "    plt.legend()\n",
    "    plt.savefig('ToymodelNNA EXP(1.5) plot_pdf: N'+str(i)+'.png')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(N_nodes[t]):\n",
    "    plt.scatter(X_val[:,i], outcome[:,i], label=\"fitted set\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "### NORMALIZATION ###\n",
    "\n",
    "# Check PDF created by Python scipy.stats.expon and PDF created myself\n",
    "y_check = np.array([[lambd*math.exp(-lambd*X_val[:,j][i]) for i in range(len(X_val[:,0]))] for j in range(N_nodes[t])])\n",
    "\n",
    "for i in range(N_nodes[t]):\n",
    "    plt.plot(X_val[:,i], y_check[i,:])\n",
    "    plt.scatter(X_val[:,i], outcome[:,i], label=\"fitted set\")\n",
    "    plt.scatter(X_val[:,i], expon.pdf(X_val[:,i],scale=1/lambd), label=\"actual PDF\")\n",
    "    plt.show()\n",
    "\n",
    "sum_temp = np.zeros(N_nodes[t])\n",
    "for j in range(N_nodes[t]):\n",
    "    for i in range(len(X_val[:,j])-1):\n",
    "        sum_temp[j] += ((y_check[j,:][i]+y_check[j,:][i+1])/2)*(X_val[:,j][i+1]-X_val[:,j][i])\n",
    "print('area under the curve of scipy.stats.expon.pdf \\t', sum_temp)\n",
    "\n",
    "sum_temp_fitted = np.zeros(N_nodes[t])\n",
    "for j in range(N_nodes[t]):\n",
    "    for i in range(len(X_val[:,j])-1):\n",
    "        sum_temp_fitted[j] += ((outcome[:,j][i]+outcome[:,j][i+1])/2)*(X_val[:,j][i+1]-X_val[:,j][i])\n",
    "print('area under the curve of the fitted pdf \\t\\t', sum_temp_fitted, '\\n')\n",
    "\n",
    "#normalization\n",
    "new_exponcdf = np.array([[x/sum_temp[j] for x in y_check[j,:]] for j in range(N_nodes[t])])\n",
    "new_outcome = np.array([[x/sum_temp_fitted[j] for x in outcome[:,j]] for j in range(N_nodes[t])])\n",
    "\n",
    "sum_temp = np.zeros(N_nodes[t])\n",
    "for j in range(N_nodes[t]):\n",
    "    for i in range(len(X_val[:,j])-1):\n",
    "        sum_temp[j] += ((new_exponcdf[j,:][i]+new_exponcdf[j,:][i+1])/2)*(X_val[:,j][i+1]-X_val[:,j][i])\n",
    "print('area under the curve of scipy.stats.expon.pdf after normalization \\t', sum_temp)\n",
    "\n",
    "sum_temp_fitted = np.zeros(N_nodes[t])\n",
    "for j in range(N_nodes[t]):\n",
    "    for i in range(len(X_val[:,j])-1):\n",
    "        sum_temp_fitted[j] += ((new_outcome[j,:][i]+new_outcome[j,:][i+1])/2)*(X_val[:,j][i+1]-X_val[:,j][i])\n",
    "print('area under the curve of the fitted pdf after normalization \\t\\t', sum_temp_fitted)\n",
    "\n",
    "for i in range(N_nodes[t]):\n",
    "    plt.scatter(X_val[:,i], new_outcome[i,:], label=\"fitted set\")\n",
    "    plt.scatter(X_val[:,i], expon.pdf(X_val[:,i],scale=1/lambd), label=\"actual PDF\")\n",
    "    plt.legend()\n",
    "    plt.savefig('ToymodelNNA EXP(1.5) plot_normalized_pdf: N'+str(i)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
